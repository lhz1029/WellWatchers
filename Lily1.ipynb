{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Status of Wells Across Tanzania\n",
    "\n",
    "Exploration done by WellWatchers Avi Saraf, Lily Zhang, and Cindy Zhao."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_values = pd.read_csv(\"clean_training_set_values.csv\")\n",
    "df_labels = pd.read_csv(\"training_set_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#merge the features (i.e. values) and the labels into one DataFrame\n",
    "df = pd.merge(df_values, df_labels, on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>basin</th>\n",
       "      <th>subvillage</th>\n",
       "      <th>region</th>\n",
       "      <th>...</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>date_recorded_offset_days</th>\n",
       "      <th>date_recorded_month</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>6000</td>\n",
       "      <td>Other</td>\n",
       "      <td>1390</td>\n",
       "      <td>Other</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Mnyusi B</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>...</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>1024</td>\n",
       "      <td>Mar</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>1399</td>\n",
       "      <td>Other</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Nyamara</td>\n",
       "      <td>Mara</td>\n",
       "      <td>...</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>301</td>\n",
       "      <td>Mar</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25</td>\n",
       "      <td>Other</td>\n",
       "      <td>686</td>\n",
       "      <td>Other</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Majengo</td>\n",
       "      <td>Manyara</td>\n",
       "      <td>...</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>310</td>\n",
       "      <td>Feb</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>0</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263</td>\n",
       "      <td>Other</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>Mahakamani</td>\n",
       "      <td>Mtwara</td>\n",
       "      <td>...</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>338</td>\n",
       "      <td>Jan</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Kyanyamisa</td>\n",
       "      <td>Kagera</td>\n",
       "      <td>...</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>903</td>\n",
       "      <td>Jul</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  amount_tsh  funder  gps_height installer  longitude   latitude  \\\n",
       "0  69572        6000   Other        1390     Other  34.938093  -9.856322   \n",
       "1   8776           0   Other        1399     Other  34.698766  -2.147466   \n",
       "2  34310          25   Other         686     Other  37.460664  -3.821329   \n",
       "3  67743           0  Unicef         263     Other  38.486161 -11.155298   \n",
       "4  19728           0   Other           0     Other  31.130847  -1.825359   \n",
       "\n",
       "                     basin  subvillage   region       ...            quantity  \\\n",
       "0               Lake Nyasa    Mnyusi B   Iringa       ...              enough   \n",
       "1            Lake Victoria     Nyamara     Mara       ...        insufficient   \n",
       "2                  Pangani     Majengo  Manyara       ...              enough   \n",
       "3  Ruvuma / Southern Coast  Mahakamani   Mtwara       ...                 dry   \n",
       "4            Lake Victoria  Kyanyamisa   Kagera       ...            seasonal   \n",
       "\n",
       "  quantity_group                source           source_type source_class  \\\n",
       "0         enough                spring                spring  groundwater   \n",
       "1   insufficient  rainwater harvesting  rainwater harvesting      surface   \n",
       "2         enough                   dam                   dam      surface   \n",
       "3            dry           machine dbh              borehole  groundwater   \n",
       "4       seasonal  rainwater harvesting  rainwater harvesting      surface   \n",
       "\n",
       "               waterpoint_type waterpoint_type_group  \\\n",
       "0           communal standpipe    communal standpipe   \n",
       "1           communal standpipe    communal standpipe   \n",
       "2  communal standpipe multiple    communal standpipe   \n",
       "3  communal standpipe multiple    communal standpipe   \n",
       "4           communal standpipe    communal standpipe   \n",
       "\n",
       "  date_recorded_offset_days date_recorded_month    status_group  \n",
       "0                      1024                 Mar      functional  \n",
       "1                       301                 Mar      functional  \n",
       "2                       310                 Feb      functional  \n",
       "3                       338                 Jan  non functional  \n",
       "4                       903                 Jul      functional  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exploratory analysis\n",
    "\n",
    "##Categorical Features\n",
    "\n",
    "We have the following categorical variables:\n",
    "- funder\n",
    "- installer\n",
    "- basin\n",
    "- subvillage\n",
    "- region\n",
    "- scheme_management\n",
    "- management\n",
    "- management_group\n",
    "- public_meeting (T/F)\n",
    "- permit (T/F)\n",
    "- extraction_type\n",
    "- extraction_type_group\n",
    "- extraction_type_class\n",
    "- payment\n",
    "- payment_type\n",
    "- water_quality\n",
    "- quality_group\n",
    "- waterpoint_type\n",
    "- waterpoint_type_group\n",
    "\n",
    "Here we see the unique values under the columns with categorical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Redundancies\n",
    "We see that some of the columns describe the same feature but have slightly different sets of values. This is particularly the case with features that also have a corresponding '_ _group_' column as well. For now, we will stick with the group features so we have fewer categorical values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gravity' 'submersible' 'swn 80' 'nira/tanira' 'india mark ii' 'other'\n",
      " 'ksb' 'mono' 'windmill' 'afridev' 'other - rope pump' 'india mark iii'\n",
      " 'other - swn 81' 'other - play pump' 'cemo' 'climax' 'walimi']\n",
      "['gravity' 'submersible' 'swn 80' 'nira/tanira' 'india mark ii' 'other'\n",
      " 'mono' 'wind-powered' 'afridev' 'rope pump' 'india mark iii'\n",
      " 'other handpump' 'other motorpump']\n",
      "['gravity' 'submersible' 'handpump' 'other' 'motorpump' 'wind-powered'\n",
      " 'rope pump']\n"
     ]
    }
   ],
   "source": [
    "print pd.Series(df.extraction_type.ravel()).unique()\n",
    "#less specific\n",
    "print pd.Series(df.extraction_type_group.ravel()).unique()\n",
    "print pd.Series(df.extraction_type_class.ravel()).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pay annually' 'never pay' 'pay per bucket' 'unknown'\n",
      " 'pay when scheme fails' 'other' 'pay monthly']\n",
      "['annually' 'never pay' 'per bucket' 'unknown' 'on failure' 'other'\n",
      " 'monthly']\n"
     ]
    }
   ],
   "source": [
    "#equivalent\n",
    "print pd.Series(df.payment.ravel()).unique()\n",
    "print pd.Series(df.payment_type.ravel()).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['communal standpipe' 'communal standpipe multiple' 'hand pump' 'other'\n",
      " 'improved spring' 'cattle trough' 'dam']\n",
      "['communal standpipe' 'hand pump' 'other' 'improved spring' 'cattle trough'\n",
      " 'dam']\n"
     ]
    }
   ],
   "source": [
    "#the difference here is the addition of 'communal standpipe multiple' in waterpoint_type\n",
    "print pd.Series(df.waterpoint_type.ravel()).unique()\n",
    "#less specific\n",
    "print pd.Series(df.waterpoint_type_group.ravel()).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['soft' 'salty' 'milky' 'unknown' 'fluoride' 'coloured' 'salty abandoned'\n",
      " 'fluoride abandoned']\n",
      "['good' 'salty' 'milky' 'unknown' 'fluoride' 'colored']\n"
     ]
    }
   ],
   "source": [
    "print pd.Series(df.water_quality.ravel()).unique()\n",
    "#less specific\n",
    "print pd.Series(df.quality_group.ravel()).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spring' 'rainwater harvesting' 'dam' 'borehole' 'other' 'shallow well'\n",
      " 'river/lake']\n",
      "['spring' 'rainwater harvesting' 'dam' 'machine dbh' 'other' 'shallow well'\n",
      " 'river' 'hand dtw' 'lake' 'unknown']\n",
      "['groundwater' 'surface' 'unknown']\n"
     ]
    }
   ],
   "source": [
    "#less specific\n",
    "#'borehole' includes 'machine dbh' and 'hand dtw'\n",
    "#'river/lake' includes 'river' and 'lake'\n",
    "#'other' includes 'other' and 'unknown'\n",
    "print pd.Series(df.source_type.ravel()).unique()\n",
    "print pd.Series(df.source.values.ravel()).unique()\n",
    "#source and source_type are nested within source_class\n",
    "print pd.Series(df.source_class.values.ravel()).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vwc' 'wug' 'other' 'private operator' 'water board' 'wua' 'company'\n",
      " 'water authority' 'parastatal' 'unknown' 'other - school' 'trust']\n",
      "['user-group' 'other' 'commercial' 'parastatal' 'unknown']\n"
     ]
    }
   ],
   "source": [
    "#management is nested within management_group\n",
    "print pd.Series(df.management.ravel()).unique()\n",
    "print pd.Series(df.management_group.ravel()).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that some of these features are redundant, so we delete one of the columns of these repeats. Regarding the features/feature_group label pairs, there is a nesting structure but it is so slight that we just delete one of the columns; otherwise, we would most likely run into problems of collinearity. We have two new dataframes, one with only the feature_group labels (less specific), and one with only the feature labels (more specific). We will try our regression on the less specific df_new first but keep df_new1 just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_new1 = df.drop(['quantity_group','extraction_type_group','waterpoint_type_group','quality_group','source_type','payment', 'construction_year','latitude','longitude', 'subvillage','id'], axis=1)\n",
    "df_new = df.drop(['quantity_group','extraction_type','waterpoint_type','quality_group','source','payment', 'construction_year','latitude','longitude','subvillage','id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>basin</th>\n",
       "      <th>region</th>\n",
       "      <th>population</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>scheme_management</th>\n",
       "      <th>permit</th>\n",
       "      <th>...</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quantity</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>date_recorded_offset_days</th>\n",
       "      <th>date_recorded_month</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000</td>\n",
       "      <td>Other</td>\n",
       "      <td>1390</td>\n",
       "      <td>Other</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>109</td>\n",
       "      <td>True</td>\n",
       "      <td>VWC</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>user-group</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>1024</td>\n",
       "      <td>Mar</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>1399</td>\n",
       "      <td>Other</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Mara</td>\n",
       "      <td>280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>301</td>\n",
       "      <td>Mar</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>Other</td>\n",
       "      <td>686</td>\n",
       "      <td>Other</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Manyara</td>\n",
       "      <td>250</td>\n",
       "      <td>True</td>\n",
       "      <td>VWC</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>user-group</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>310</td>\n",
       "      <td>Feb</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263</td>\n",
       "      <td>Other</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>Mtwara</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>VWC</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>dry</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>338</td>\n",
       "      <td>Jan</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Kagera</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>other</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>903</td>\n",
       "      <td>Jul</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh  funder  gps_height installer                    basin   region  \\\n",
       "0        6000   Other        1390     Other               Lake Nyasa   Iringa   \n",
       "1           0   Other        1399     Other            Lake Victoria     Mara   \n",
       "2          25   Other         686     Other                  Pangani  Manyara   \n",
       "3           0  Unicef         263     Other  Ruvuma / Southern Coast   Mtwara   \n",
       "4           0   Other           0     Other            Lake Victoria   Kagera   \n",
       "\n",
       "   population public_meeting scheme_management permit       ...        \\\n",
       "0         109           True               VWC  False       ...         \n",
       "1         280            NaN             Other   True       ...         \n",
       "2         250           True               VWC   True       ...         \n",
       "3          58           True               VWC   True       ...         \n",
       "4           0           True               NaN   True       ...         \n",
       "\n",
       "  management_group payment_type water_quality      quantity  \\\n",
       "0       user-group     annually          soft        enough   \n",
       "1       user-group    never pay          soft  insufficient   \n",
       "2       user-group   per bucket          soft        enough   \n",
       "3       user-group    never pay          soft           dry   \n",
       "4            other    never pay          soft      seasonal   \n",
       "\n",
       "            source_type source_class waterpoint_type_group  \\\n",
       "0                spring  groundwater    communal standpipe   \n",
       "1  rainwater harvesting      surface    communal standpipe   \n",
       "2                   dam      surface    communal standpipe   \n",
       "3              borehole  groundwater    communal standpipe   \n",
       "4  rainwater harvesting      surface    communal standpipe   \n",
       "\n",
       "  date_recorded_offset_days date_recorded_month    status_group  \n",
       "0                      1024                 Mar      functional  \n",
       "1                       301                 Mar      functional  \n",
       "2                       310                 Feb      functional  \n",
       "3                       338                 Jan  non functional  \n",
       "4                       903                 Jul      functional  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Nestings\n",
    "\n",
    "In df_new, we know that:\n",
    "- management is nested within management_group\n",
    "- source is nested within source_class\n",
    "- extraction is nested within extraction_type_class\n",
    "- subvillage is nested within region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Grouping the types of categorical variables\n",
    "The features dealing with the management of the well include:\n",
    "- funder\n",
    "- installer\n",
    "- scheme_management\n",
    "- management/management_group\n",
    "- payment_type\n",
    "- permit (T/F)\n",
    "\n",
    "The features dealing with the creation of the well include:\n",
    "- extraction/extraction_type_class\n",
    "- waterpoint_type\n",
    "\n",
    "The features dealing with time include: \n",
    "- construction_year\n",
    "- date_recorded_offset_days (int; how long ago it was constructed, from the date recorded)\n",
    "- date_recorded_month\n",
    "\n",
    "The features dealing with natural properties include:\n",
    "- water_quality\n",
    "- source/source_class\n",
    "- amount_tsh\n",
    "- quantity\n",
    "- basin\n",
    "\n",
    "The features dealing with the community using the well and location include:\n",
    "- subvillage\n",
    "- region\n",
    "- population\n",
    "- public_meeting (T/F)\n",
    "- gps_height\n",
    "- longitude\n",
    "- latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'amount_tsh', u'funder', u'gps_height', u'installer', u'basin',\n",
       "       u'subvillage', u'region', u'population', u'public_meeting',\n",
       "       u'scheme_management', u'permit', u'extraction_type_group',\n",
       "       u'extraction_type_class', u'management', u'management_group',\n",
       "       u'payment_type', u'water_quality', u'quantity', u'source_type',\n",
       "       u'source_class', u'waterpoint_type_group', u'date_recorded_offset_days',\n",
       "       u'date_recorded_month', u'status_group'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Splitting the training and testing data\n",
    "\n",
    "We split the data into training and test sets so we can check our models' accuracy on a holdout set to see if they are in fact generalizable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train, test = train_test_split(xrange(df_new.shape[0]), train_size=0.7)\n",
    "mask=np.ones(df_new.shape[0])\n",
    "mask[train]=1\n",
    "mask[test]=0\n",
    "mask = (mask==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Standardize\n",
    "We now standardize our quantitative variables so they can be compared. These variables are amount_tsh, gps_height, population, and date_recorded_offset_days. We keep a non-standardized copy just so we can compare the fit of from a model with standardized vs. nonstandardized features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keep a copy of df_new that is not standardized\n",
    "df_copy = df_new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>population</th>\n",
       "      <th>date_recorded_offset_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.831495</td>\n",
       "      <td>1.042939</td>\n",
       "      <td>-0.148715</td>\n",
       "      <td>1.135927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.101290</td>\n",
       "      <td>1.055942</td>\n",
       "      <td>0.205933</td>\n",
       "      <td>-1.021636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.093236</td>\n",
       "      <td>0.025834</td>\n",
       "      <td>0.143714</td>\n",
       "      <td>-0.994778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.101290</td>\n",
       "      <td>-0.585296</td>\n",
       "      <td>-0.254488</td>\n",
       "      <td>-0.911221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.101290</td>\n",
       "      <td>-0.965266</td>\n",
       "      <td>-0.374778</td>\n",
       "      <td>0.774841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh  gps_height  population  date_recorded_offset_days\n",
       "0    1.831495    1.042939   -0.148715                   1.135927\n",
       "1   -0.101290    1.055942    0.205933                  -1.021636\n",
       "2   -0.093236    0.025834    0.143714                  -0.994778\n",
       "3   -0.101290   -0.585296   -0.254488                  -0.911221\n",
       "4   -0.101290   -0.965266   -0.374778                   0.774841"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing as prepr\n",
    "STANDARDIZABLE = [u'amount_tsh', u'gps_height', u'population', u'date_recorded_offset_days']\n",
    "scaler = prepr.StandardScaler().fit(df_new[mask][STANDARDIZABLE])\n",
    "df_new[STANDARDIZABLE] = scaler.transform(df_new[STANDARDIZABLE])\n",
    "df_new[STANDARDIZABLE].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Visualizing the feature variables\n",
    "Let's plot these variables now and see how their distributions differ across the functional, non functional, and needs repair wells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "# for i, feature in enumerate(STANDARDIZABLE):\n",
    "#     ax = axes[i/2, i%2]\n",
    "#     sns.kdeplot(df_new[df_new['status_group']=='functional'][feature], ax=ax, shade=True,color='green', label=\"Functional wells\")\n",
    "#     sns.kdeplot(df_new[df_new['status_group']=='non functional'][feature], ax=ax, shade=True,color='red', label=\"Non Functional Wells\")\n",
    "#     sns.kdeplot(df_new[df_new['status_group']=='functional needs repair'][feature], ax=ax, shade=True,color='blue', label=\"Wells that Need Repair\")\n",
    "#     ax.set_title(feature)\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same for the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CATEGORICAL = [u'funder', u'installer', u'basin', u'region',\n",
    "               u'public_meeting', u'scheme_management', u'permit',\n",
    "               u'extraction_type_group', u'extraction_type_class',\n",
    "               u'management', u'management_group', u'payment_type', u'water_quality',\n",
    "               u'quantity', u'source_type', u'source_class', u'waterpoint_type_group', u'date_recorded_month']\n",
    "for variable in CATEGORICAL:\n",
    "    df_new[variable] = df_new[variable].astype('category')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fig1, axes1 = plt.subplots(5,4)\n",
    "\n",
    "# plt.rc('xtick', labelsize=10) \n",
    "# plt.rc('ytick', labelsize=10) \n",
    "# for j, variable in enumerate(CATEGORICAL):\n",
    "#     ax1 = axes1[j/4,j%4]\n",
    "#     functional = df_new[df_new['status_group']=='functional'][variable].tolist()\n",
    "#     non_functional = df_new[df_new['status_group']=='non functional'][variable].tolist()\n",
    "#     needs_repair = df_new[df_new['status_group']=='functional needs repair'][variable].tolist()\n",
    "#     categories = pd.Series(df_new[variable].values.ravel()).unique()\n",
    "#     value_freq_funct = []\n",
    "#     value_freq_nonf = []\n",
    "#     value_freq_repair = []\n",
    "#     categories_num = range(1,len(categories)+1)\n",
    "#     for value in categories:\n",
    "#         value_freq_funct.append(functional.count(value))\n",
    "#         value_freq_nonf.append(non_functional.count(value))\n",
    "#         value_freq_repair.append(needs_repair.count(value))\n",
    "#     ax1.bar(categories_num,value_freq_funct,align='center',color='g')\n",
    "#     ax1.bar(categories_num,value_freq_nonf,align='center',color='r')\n",
    "#     ax1.bar(categories_num,value_freq_repair,align='center',color='b')\n",
    "#     ax1.set_xticklabels(categories)\n",
    "#     ax1.legend()\n",
    "#     ax1.set_title(variable)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at some of them. In particular, ___ seem to show very interesting distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##To run\n",
    "#for subvillages\n",
    "# functional = df_new[df_new['status_group']=='functional']['subvillage'].tolist()\n",
    "# non_functional = df_new[df_new['status_group']=='non functional']['subvillage'].tolist()\n",
    "# needs_repair = df_new[df_new['status_group']=='functional needs repair']['subvillage'].tolist()\n",
    "\n",
    "# plt.rc('xtick', labelsize=12) \n",
    "# plt.rc('ytick', labelsize=12)\n",
    "\n",
    "# categories = pd.Series(df_new.subvillage.values.ravel()).unique()\n",
    "# value_freq_funct = []\n",
    "# value_freq_nonf = []\n",
    "# value_freq_repair = []\n",
    "# categories_num = range(1,len(categories)+1)\n",
    "# for value in categories:\n",
    "#     value_freq_funct.append(functional.count(value))\n",
    "#     value_freq_nonf.append(non_functional.count(value))\n",
    "#     value_freq_repair.append(needs_repair.count(value))\n",
    "# fig, [ax1, ax2, ax3] = plt.subplots(3, 1)\n",
    "# ax1.bar(categories_num,value_freq_funct,align='center',color='g')\n",
    "# ax2.bar(categories_num,value_freq_nonf,align='center',color='r')\n",
    "# ax3.bar(categories_num,value_freq_repair,align='center',color='b')\n",
    "#plt.xticks(categories_num, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x10d713410>,\n",
       "  <matplotlib.axis.XTick at 0x10d713910>,\n",
       "  <matplotlib.axis.XTick at 0x10cbc1850>,\n",
       "  <matplotlib.axis.XTick at 0x10cf870d0>,\n",
       "  <matplotlib.axis.XTick at 0x10cf87850>,\n",
       "  <matplotlib.axis.XTick at 0x10cf87fd0>,\n",
       "  <matplotlib.axis.XTick at 0x10cf90790>,\n",
       "  <matplotlib.axis.XTick at 0x10cf90f10>,\n",
       "  <matplotlib.axis.XTick at 0x10cf9a6d0>,\n",
       "  <matplotlib.axis.XTick at 0x10cf9ae50>,\n",
       "  <matplotlib.axis.XTick at 0x10cfa3610>],\n",
       " <a list of 11 Text xticklabel objects>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAwQAAAITCAYAAAC5X9t1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzs3XlAVWXi//EP4laUYaWAubRMIpphuaQJlIIYm4jmQpbL\n",
       "qGlSVtJoLu1uY45OaJmNmZOlYpbLz6EsRVOpFG03XCYVNy5o5g4o8Pz+8MsdSRRFCPB5v/6Sc+89\n",
       "PM/lLud9zzlXF2OMEQAAAAArVSrrAQAAAAAoOwQBAAAAYDGCAAAAALAYQQAAAABYjCAAAAAALEYQ\n",
       "AAAAABa7pCBYunSpIiMjFRUVpejoaG3ZskV5eXkaO3asQkJC1LFjRy1YsMB5/dTUVPXq1UthYWHq\n",
       "3r27du7c6bxs0aJFCg0NVceOHfXKK68oNzdXkpSVlaXY2FiFhoYqJCREK1euLOGpAgAAAPijykVd\n",
       "YdeuXZo8ebKWLFmim266SV9++aWefPJJDRw4UHv37lVCQoKOHz+uHj16qEmTJmratKmee+459evX\n",
       "T6GhoVq7dq2GDh2q5cuXa/v27Zo+fbqWLFkid3d3xcbGas6cOerfv7/i4uLk5uamhIQEpaWlqXv3\n",
       "7mratKk8PDz+jPsBAAAAsFKRewiqVq2qsWPH6qabbpIkNW3aVAcPHtSKFSvUpUsXubi4qEaNGgoL\n",
       "C9OyZcuUnp6uXbt2KTQ0VJIUEBCgzMxMpaSkKDExUYGBgXJ3d5ck9ejRQ8uWLZMkrVq1St27d5ck\n",
       "eXl5yc/PT59++mmpTBoAAADAWUXuIbjlllt0yy23OH+eMGGCAgMDtWPHDnl5eTmXe3h4aPv27XI4\n",
       "HKpdu3aBdXh4eMjhcCgtLU1169Z1Lvf09JTD4ZAkpaWlnbe+9PT04s8MAAAAQJEu+aTizMxMDR06\n",
       "VHv37tW4ceOcx/4XWFmlSsrLyyv8F1WqJGPMectdXV0lqdDbVarEOc8AAABAaSpyD4EkHThwQE88\n",
       "8YT+8pe/6P3331fVqlVVp04dZWRkOK+Tnp4uT09P1alTRwcPHixw+/zLvLy8ClyWv1yS83b5hyal\n",
       "p6ercePGlz2hzZs3X/ZtAAAAABs0b978vGVFBsHRo0f16KOPqmvXroqJiXEuDwwM1Mcff6x27drp\n",
       "5MmTSkhI0KuvvioPDw/Vr19fCQkJCg0N1bp16+Tq6ipvb29JUkxMjAYPHqyaNWsqPj5eQUFBzvXF\n",
       "x8frpZdeksPh0Pr16zVkyJASm+ifbd26dQp4L0BqUNYjKaZUaW2/tfL39y/rkUiSUlJSJEk+Pj5l\n",
       "PJLSZ9NcJbvma9NcJbvma9NcJbvma9NcJbvma9Nc813og/Mig2D+/PlKT0/XypUr9cUXX0iSXFxc\n",
       "9O6772rPnj2KjIzUmTNnFB0drRYtWkiSpk6dqtGjR2vGjBmqVq2a4uLiJEne3t6KiYlRnz59lJOT\n",
       "I19fXw0YMECS9NRTT+nll19WeHi48vLyNGLECNWrV69EJg8AAACgcEUGweDBgzV48OBCLxs1alSh\n",
       "y+vXr6+5c+cWellUVJSioqLOW37ttddq0qRJRQ0HAAAAQAnirF0AAADAYgQBAAAAYDGCAAAAALAY\n",
       "QQAAAABYjCAAAAAALEYQAAAAABYjCAAAAACLEQQAAACAxQgCAAAAwGIEAQAAAGAxggAAAACwGEEA\n",
       "AAAAWIwgAAAAACxGEAAAAAAWIwgAAAAAixEEAAAAgMUIAgAAAMBiBAEAAABgMYIAAAAAsBhBAAAA\n",
       "AFiMIAAAAAAsRhAAAAAAFiMIAAAAAIsRBAAAAIDFCAIAAADAYgQBAAAAYDGCAAAAALAYQQAAAABY\n",
       "jCAAAAAALEYQAAAAABYjCAAAAACLEQQAAACAxQgCAAAAwGIEAQAAAGAxggAAAACwGEEAAAAAWIwg\n",
       "AAAAACxGEAAAAAAWIwgAAAAAixEEAAAAgMUIAgAAAMBiBAEAAABgMYIAAAAAsBhBAAAAAFiMIAAA\n",
       "AAAsRhAAAAAAFiMIAAAAAIsRBAAAAIDFCAIAAADAYgQBAAAAYDGCAAAAALAYQQAAAABYjCAAAAAA\n",
       "LEYQAAAAABYjCAAAAACLEQQAAACAxQgCAAAAwGIEAQAAAGAxggAAAACwGEEAAAAAWIwgAAAAACxG\n",
       "EAAAAAAWIwgAAAAAixEEAAAAgMUIAgAAAMBiBAEAAABgMYIAAAAAsBhBAAAAAFiMIAAAAAAsRhAA\n",
       "AAAAFiMIAAAAAIsRBAAAAIDFCAIAAADAYgQBAAAAYDGCAAAAALAYQQAAAABYjCAAAAAALEYQAAAA\n",
       "ABYjCAAAAACLEQQAAACAxQgCAAAAwGIEAQAAAGAxggAAAACwGEEAAAAAWIwgAAAAACxGEAAAAAAW\n",
       "IwgAAAAAixEEAAAAgMUIAgAAAMBiBAEAAABgMYIAAAAAsBhBAAAAAFiMIAAAAAAsRhAAAAAAFiMI\n",
       "AAAAAIsRBAAAAIDFCAIAAADAYgQBAAAAYDGCAAAAALAYQQAAAABYjCAAAAAALEYQAAAAABYjCAAA\n",
       "AACLEQQAAACAxQgCAAAAwGIEAQAAAGAxggAAAACwGEEAAAAAWIwgAAAAACxGEAAAAAAWIwgAAAAA\n",
       "ixEEAAAAgMUIAgAAAMBiBAEAAABgscqXesWRI0eqYcOG6tevnySpdevW8vLycl7ev39/hYeHKzU1\n",
       "VaNGjdKRI0fk5uamiRMn6vbbb5ckLVq0SLNnz1Zubq7uv/9+jRkzRq6ursrKytLo0aOVkpIiY4xi\n",
       "Y2MVFBRUwlMFAAAA8EdFBsGvv/6qV199VT/++KMaNmwoSdq1a5fc3d21ePHi867/3HPPqV+/fgoN\n",
       "DdXatWs1dOhQLV++XNu3b9f06dO1ZMkSubu7KzY2VnPmzFH//v0VFxcnNzc3JSQkKC0tTd27d1fT\n",
       "pk3l4eFR8jMGAAAA4FTkIUPz5s1T165d9dBDDzmXfffdd6pUqZJ69+6tTp066c0335QxRunp6dq1\n",
       "a5dCQ0MlSQEBAcrMzFRKSooSExMVGBgod3d3SVKPHj20bNkySdKqVavUvXt3SZKXl5f8/Pz06aef\n",
       "lvhkAQAAABRU5B6CF154QZL09ddfO5fl5uaqbdu2GjFihLKysjRw4EBdf/318vX1Ve3atQvc3sPD\n",
       "Qw6HQ2lpaapbt65zuaenpxwOhyQpLS2twOFHHh4eSk9PL/akUlJSin3bkrJ79+6yHsIV2717t26+\n",
       "+eayHoYkKTMzU1L5+NuWNpvmKtk1X5vmKtk1X5vmKtk1X5vmKtk1X5vmWpRLPofgXN26dXP++7rr\n",
       "rlO/fv00d+5cNW3atNDrV6pUScaY85a7urpKkvLy8gq9DQAAAIDSVawgWLp0qRo1aiRvb29JkjFG\n",
       "VapUUZ06dXTw4MEC101PT5enp6e8vLwKXJa/XJLzdjfddJPzssaNGxdrQpLk4+NT7NuWlEOHDpX1\n",
       "EK7YrbfeWi7uS+l/9V5exlOabJqrZNd8bZqrZNd8bZqrZNd8bZqrZNd8bZprvs2bNxe6vFgfw+/Y\n",
       "sUPTpk1TXl6esrKy9MEHHyg0NFQeHh6qX7++EhISJEnr1q2Tq6urvL291b59eyUmJurw4cMyxig+\n",
       "Pt75TUKBgYGKj4+XJDkcDq1fv14PPvhgcYYGAAAA4DIUKwiefPJJ3XDDDYqIiFBkZKSaN2+uhx9+\n",
       "WJI0depUzZ8/XxEREXrjjTcUFxcnSfL29lZMTIz69Omj0NBQVa5cWQMGDJAkPfXUUzp58qTCw8P1\n",
       "17/+VSNGjFC9evVKaIoAAAAALuSSDxmaMGGC89/Vq1fXuHHjCr1e/fr1NXfu3EIvi4qKUlRU1HnL\n",
       "r732Wk2aNOlShwIAAACghHDmLgAAAGAxggAAAACwGEEAAAAAWIwgAAAAACxGEAAAAAAWIwgAAAAA\n",
       "ixEEAAAAgMUIAgAAAMBiBAEAAABgMYIAAAAAsBhBAAAAAFiMIAAAAAAsRhAAAAAAFiMIAAAAAIsR\n",
       "BAAAAIDFCAIAAADAYgQBAAAAYDGCAAAAALAYQQAAAABYjCAAAAAALEYQAAAAABYjCAAAAACLEQQA\n",
       "AACAxQgCAAAAwGIEAQAAAGAxggAAAACwGEEAAAAAWIwgAAAAACxGEAAAAAAWIwgAAAAAixEEAAAA\n",
       "gMUIAgAAAMBiBAEAAABgMYIAAAAAsBhBAAAAAFiMIAAAAAAsRhAAAAAAFiMIAAAAAIsRBAAAAIDF\n",
       "CAIAAADAYgQBAAAAYDGCAAAAALAYQQAAAABYjCAAAAAALEYQAAAAABYjCAAAAACLEQQAAACAxQgC\n",
       "AAAAwGIEAQAAAGAxggAAAACwGEEAAAAAWIwgAAAAACxGEAAAAAAWIwgAAAAAixEEAAAAgMUIAgAA\n",
       "AMBiBAEAAABgMYIAAAAAsBhBAAAAAFiMIAAAAAAsRhAAAAAAFiMIAAAAAIsRBAAAAIDFCAIAAADA\n",
       "YgQBAAAAYDGCAAAAALAYQQAAAABYjCAAAAAALEYQAAAAABarXNYDuFplZ2dLjrIexRVw/N8cAAAA\n",
       "cFUjCErJ1q1bNe1TybesB1JMP0jaGrpVQUFBZT0UAAAAlCKCoBT5SvIv60FcgR/KegAAAAAodZxD\n",
       "AAAAAFiMIAAAAAAsRhAAAAAAFiMIAAAAAIsRBAAAAIDFCAIAAADAYgQBAAAAYDGCAAAAALAYQQAA\n",
       "AABYjCAAAAAALEYQAAAAABYjCAAAAACLEQQAAACAxQgCAAAAwGIEAQAAAGAxggAAAACwGEEAAAAA\n",
       "WIwgAAAAACxGEAAAAAAWIwgAAAAAixEEAAAAgMUIAgAAAMBiBAEAAABgMYIAAAAAsBhBAAAAAFiM\n",
       "IAAAAAAsRhAAAAAAFiMIAAAAAIsRBAAAAIDFCAIAAADAYgQBAAAAYDGCAAAAALAYQQAAAABYjCAA\n",
       "AAAALEYQAAAAABYjCAAAAACLEQQAAACAxQgCAAAAwGIEAQAAAGAxggAAAACwGEEAAAAAWIwgAAAA\n",
       "ACx2yUEwcuRIvffee5KkvLw8jRs3TiEhIerYsaMWLFjgvF5qaqp69eqlsLAwde/eXTt37nRetmjR\n",
       "IoWGhqpjx4565ZVXlJubK0nKyspSbGysQkNDFRISopUrV5bU/AAAAABcRJFB8Ouvv6pPnz767LPP\n",
       "nMvmz5+vPXv2KCEhQR999JH+/e9/66effpIkPffcc+rVq5f+85//6Mknn9TQoUMlSdu3b9f06dM1\n",
       "b948rVixQseOHdOcOXMkSXFxcXJzc1NCQoJmz56tV155Renp6aUwXQAAAADnKjII5s2bp65du+qh\n",
       "hx5yLlu1apW6dOkiFxcX1ahRQ2FhYVq2bJnS09O1a9cuhYaGSpICAgKUmZmplJQUJSYmKjAwUO7u\n",
       "7pKkHj16aNmyZc71de/eXZLk5eUlPz8/ffrppyU+WQAAAAAFVS7qCi+88IIk6euvv3YuS0tLk5eX\n",
       "l/NnDw8Pbd++XQ6HQ7Vr1y5wew8PDzkcDqWlpalu3brO5Z6ennI4HBdc35XsIUhJSSn2bUuKw+GQ\n",
       "b1kP4go5HI5ycV9KUmZmpqTy8bctbTbNVbJrvjbNVbJrvjbNVbJrvjbNVbJrvjbNtSjFOqk4Ly/v\n",
       "/BVVqlTo8vzLjDHnLXd1db3o+gAAAACUriL3EBSmTp06ysjIcP6cnp4uT09P1alTRwcPHixw3fzL\n",
       "vLy8ClyWvzx/fQcPHtRNN93kvKxx48bFGZokycfHp9i3LSn5c6vIPD09y8V9Kf2v3svLeEqTTXOV\n",
       "7JqvTXOV7JqvTXOV7JqvTXOV7JqvTXPNt3nz5kKXF+tj+MDAQH388cfKzc3VsWPHlJCQoKCgIHl4\n",
       "eKh+/fpKSEiQJK1bt06urq7y9vZW+/btlZiYqMOHD8sYo/j4eAUFBTnXFx8fL+nsYSrr16/Xgw8+\n",
       "WJyhAQAAALgMxdpDEB0drb179yoyMlJnzpxRdHS0WrRoIUmaOnWqRo8erRkzZqhatWqKi4uTJHl7\n",
       "eysmJkZ9+vRRTk6OfH19NWDAAEnSU089pZdfflnh4eHKy8vTiBEjVK9evRKaIgAAAIALueQgmDBh\n",
       "gvPfrq6uGjlyZKHXq1+/vubOnVvoZVFRUYqKijpv+bXXXqtJkyZd6lAAAAAAlBDO3AUAAAAsRhAA\n",
       "AAAAFiMIAAAAAIsRBAAAAIDFCAIAAADAYgQBAAAAYDGCAAAAALAYQQAAAABYjCAAAAAALEYQAAAA\n",
       "ABYjCAAAAACLEQQAAACAxQgCAAAAwGIEAQAAAGAxggAAAACwGEEAAAAAWIwgAAAAACxGEAAAAAAW\n",
       "IwgAAAAAixEEAAAAgMUIAgAAAMBiBAEAAABgMYIAAAAAsBhBAAAAAFiMIAAAAAAsRhAAAAAAFiMI\n",
       "AAAAAIsRBAAAAIDFCAIAAADAYgQBAAAAYDGCAAAAALAYQQAAAABYjCAAAAAALEYQAAAAABYjCAAA\n",
       "AACLEQQAAACAxQgCAAAAwGIEAQAAAGAxggAAAACwGEEAAAAAWIwgAAAAACxGEAAAAAAWIwgAAAAA\n",
       "ixEEAAAAgMUIAgAAAMBiBAEAAABgMYIAAAAAsBhBAAAAAFiMIAAAAAAsRhAAAAAAFiMIAAAAAIsR\n",
       "BAAAAIDFCAIAAADAYgQBAAAAYDGCAAAAALAYQQAAAABYjCAAAAAALEYQAAAAABYjCAAAAACLEQQA\n",
       "AACAxQgCAAAAwGIEAQAAAGAxggAAAACwGEEAAAAAWIwgAAAAACxGEAAAAAAWIwgAAAAAixEEAAAA\n",
       "gMUIAgAAAMBiBAEAAABgMYIAAAAAsBhBAAAAAFiMIAAAAAAsRhAAAAAAFiMIAAAAAIsRBAAAAIDF\n",
       "CAIAAADAYgQBAAAAYDGCAAAAALAYQQAAAABYjCAAAAAALEYQAAAAABYjCAAAAACLEQQAAACAxQgC\n",
       "AAAAwGIEAQAAAGAxggAAAACwGEEAAAAAWIwgAAAAACxGEAAAAAAWIwgAAAAAixEEAAAAgMUIAgAA\n",
       "AMBiBAEAAABgMYIAAAAAsBhBAAAAAFiMIAAAAAAsRhAAAAAAFiMIAAAAAIsRBAAAAIDFCAIAAADA\n",
       "YgQBAAAAYDGCAAAAALAYQQAAAABYjCAAAAAALEYQAAAAABYjCAAAAACLEQQAAACAxQgCAAAAwGIE\n",
       "AQAAAGAxggAAAACwGEEAAAAAWIwgAAAAACxW+UpuPHHiRK1YsULu7u6SpNtuu02TJ0/W+PHjlZSU\n",
       "pLy8PPXr1089e/aUJKWmpmrUqFE6cuSI3NzcNHHiRN1+++2SpEWLFmn27NnKzc3V/fffrzFjxsjV\n",
       "1fUKpwcAAADgYq4oCL7//ntNnTpVzZo1cy6bN2+e9u7dq4SEBB0/flw9evRQkyZN1LRpUz333HPq\n",
       "16+fQkNDtXbtWg0dOlTLly/X9u3bNX36dC1ZskTu7u6KjY3VnDlz1L9//yueIAAAAIALK/YhQ6dP\n",
       "n9Yvv/yi2bNnKzIyUkOHDlVaWppWrlypLl26yMXFRTVq1FBYWJiWLVum9PR07dq1S6GhoZKkgIAA\n",
       "ZWZmKiUlRYmJiQoMDHTuaejRo4eWLl1aMjMEAAAAcEHFDoKMjAy1adNGsbGxWrp0qZo1a6YhQ4Yo\n",
       "LS1NXl5ezut5eHgoPT1dDodDtWvXLrAODw8PORwOpaWlydPT07nc09NT6enpxR0aAAAAgEtU7EOG\n",
       "6tatq5kzZzp//utf/6o333xT2dnZ5123UqVKysvLK3Q9lSpVkjHmvOVXcv5ASkpKsW9bUhwOh3zL\n",
       "ehBXyOFwlIv7UpIyMzMllY+/bWmzaa6SXfO1aa6SXfO1aa6SXfO1aa6SXfO1aa5FKfYegm3btp13\n",
       "WI8xRq1atVJGRoZzWXp6ujw9PVWnTh0dPHiwwPXzL/Py8ipwWf5yAAAAAKWr2HsIKlWqpPHjx6tF\n",
       "ixa65ZZb9OGHH6pRo0YKDAzUokWL1K5dO508eVIJCQl69dVX5eHhofr16yshIUGhoaFat26dXF1d\n",
       "5e3tLUmKiYnR4MGDVbNmTcXHxyswMLDYk/Lx8Sn2bUvK1RA0np6e5eK+lP5X7+VlPKXJprlKds3X\n",
       "prlKds3XprlKds3XprlKds3Xprnm27x5c6HLix0Ed955p8aMGaPBgwcrLy9Pnp6emjJlimrVqqXU\n",
       "1FRFRkbqzJkzio6OVosWLSRJU6dO1ejRozVjxgxVq1ZNcXFxkiRvb2/FxMSoT58+ysnJka+vrwYO\n",
       "HFjcoQEAAAC4RFf0taMRERGKiIg4b/moUaMKvX79+vU1d+7cQi+LiopSVFTUlQwHAAAAwGXifyoG\n",
       "AAAALEYQAAAAABYjCAAAAACLXdE5BAAAVARZWVlKTk4utfXv3r1bknTo0KFS+x0tW7ZU9erVS239\n",
       "AOxFEAAArnrJycn6ISCg1P7DyFtLab35fpCktWvl7+9fyr8JgI0IAgCAFXwlsTkNAOfjHAIAAADA\n",
       "YgQBAAAAYDGCAAAAALAYQQAAAABYjCAAAAAALEYQAAAAABYjCAAAAACLEQQAAACAxQgCAAAAwGIE\n",
       "AQAAAGAxggAAAACwGEEAAAAAWIwgAAAAACxGEAAAAAAWIwgAAAAAixEEAAAAgMUIAgAAAMBiBAEA\n",
       "AABgMYIAAAAAsBhBAAAAAFiMIAAAXPWys7PLeghX7GqYA4DyiSAAAFz1tm7dWtZDuGJXwxwAlE8E\n",
       "AQAAAGAxggAAAACwGEEAAAAAWIwgAAAAACxGEAAAAAAWIwgAAAAAixEEAAAAgMUIAgAAAMBiBAEA\n",
       "AABgMYIAAAAAsBhBAAAAAFiMIAAAAAAsRhAAAAAAFiMIAAAAAIsRBAAAAIDFCAIAAADAYgQBAAAA\n",
       "YDGCAAAAALAYQQAAAABYjCAAAAAALEYQAAAAABYjCAAAAACLEQQAAACAxQgCAAAAwGIEAQAAAGAx\n",
       "ggAAAACwGEEAAAAAWIwgAAAAACxGEAAAAAAWIwgAAAAAixEEAAAAgMUIAgAAAMBiBAEAAABgMYIA\n",
       "AAAAsBhBAAAAAFisclkP4Gp15swZ/VDWg7gCP+jsHAAAAHB1IwhKSWpqqt7QNEm+ZT2UYvpBT6f+\n",
       "t6wHAQAAgFJGEJQqX0n+ZT2IK0AQAAAAXO04hwAAAACwGEEAAAAAWIwgAAAAACzGOQQAAFxlsrKy\n",
       "lJycXGrr3717tyTp0KFDpbL+li1bqnr16qWybgDnIwgAALjKJCcnK2BCgORZ1iMpBoe0duRa+ftX\n",
       "5C/lACoWggAAgKuRp6QGZT0IABUB5xAAAAAAFiMIAAAAAIsRBAAAAIDFCAIAAADAYpxUDOCi+PpC\n",
       "AACubgQBgIvi6wsBALi6EQQAisbXFwIAcNXiHAIAAADAYgQBAAAAYDGCAAAAALAYQQAAAABYjCAA\n",
       "AAAALEYQAAAAABYjCAAAAACLEQQAAACAxfiPyQBcVHZ2tuQo61EUk+P/xg8AAC6IIABwUVu3btW0\n",
       "TyXfsh5IMfwgaWvoVgUFBZX1UIA/FSEP4HIQBACK5CvJv6wHUUw/lPUAgDJAyAO4HAQBAABXIUIe\n",
       "wKXipGIAAADAYuwhAABLZWVlKTk5udTWv3v3bknSoUOHSmX9LVu2VPXq1Utl3QBgE4IAACyVnJys\n",
       "HwICSu0481tLab3S/x1Ssnat/P0r6kExAFB+EAQAYLGKfJw5AKBkcA4BAFiqon+1Y0UfPwCUFwQB\n",
       "AFhq69atZT2EK1LRxw8A5QVBAAAAAFiMcwiAy1TRv5lF4ttZAADA/xAEwGVKTk5WwIQAybOsR1JM\n",
       "DmntSL6dpTDEHgDARgQBUByekhqU9SBQ0oi9q9eZM2cq9P9++4POzgHnI+SvXvxt/zwEAQCci9i7\n",
       "KqWmpuoNTZNK7X9dKG0/6OnU/5b1IMolQv7qVZH/rxSpYv1/KQQBAMASFf1/XSAILoiQv2pV9Gdt\n",
       "RUEQoERU9N16FWWXHgAAQEkjCFAiKvQuW3bXAgBQ7mRnZ6taWQ/iClWU/0CRIEDJYZctAOBPlp2d\n",
       "LTnKehRXwHF5G40VfY+8dOl75bdu3Vphz/rJt3XrVgUFBZX1MIpEEACXybY3HwAoz7Zu3appn1bk\n",
       "08WlraGXvtFYoffIS+yVL6cIAuAy2fbmA6Diqchfs1qcr1it6CeeXvbfij3yKGEEAVAM1r35WIK9\n",
       "P7haVOyvWeUrVoE/G0GAElGhN6TYiML/Ye8Pri4V+aMLggD4MxEEKBEVeUOKjSicqyJvQkns/QGu\n",
       "dhX6AziJD+HKKYIAJaYib0ixEQUAqAgq8gdwEh/ClVcEAQBYyrYTT4GrRUX+AE7iQ7jyiCAAAEtx\n",
       "4ikAQCpnQbBmzRpNmTJFZ86ckbe3t8aNGyc3N7eyHhZgNZs+Ra7Ic5WK+6l5Rf6skSAAgJJQboLg\n",
       "8OHDGjVqlOLj41WvXj1NnjxZkydP1ksvvVTWQ8MlqMgbUmw0XpxNnyJX7LlKfGoO4Gpi2/ttWSo3\n",
       "QZCUlKS7775b9erVkyRFR0crMjKSIKggKvaGFBuNRbPpU+SKPFeJT81hG9s2Gm2ar53vt2Wj3ARB\n",
       "WlqaPD3/9/9we3p66uTJkzp58iSHDVUYFXlDio1GAKiIbNtotG2+vN/+OcpNEBhjCl3u6up62etK\n",
       "SUm50uFcscOHD6tin0f/gw4fPnzJ92XFnq9Nc5Xsmq9Nc5Xsmq9Nc5Xsmm9x5lqxMd8LX6/iPo6l\n",
       "y30slyUXc6Et8T/ZsmXL9Nlnn+mtt96SJO3fv19dunTRhg0bLms9mzdvLo3hAQAAABVe8+bNz1tW\n",
       "bvYQ+Pn5adKkSdqzZ4/q16+v+Ph4BQYGXvZ6CpskAAAAgMKVmz0EkrR27Vr94x//UE5OjurVq6dJ\n",
       "kyapRo0aZT0sAAAA4KpVroIAAAAAwJ+rUlkPAAAAAEDZIQgAAAAAixEEAAAAgMUIAgAAAMBiBAEA\n",
       "AABgMYIAAAAAsBhBAAAAAFiMIChH5s+fr8jISIWHhysiIkIjRoxQWlqaJOmjjz7S/PnzJUnTp0/X\n",
       "2LFjy3KoxdKoUSMdOXKkwLIVK1boscceK/K2gwYN0q+//lqs33vixAn17NlTERER+uKLL4q1jsvR\n",
       "qFEjderUSZ07d1ZUVJQeeughdevWTT///HOp/+4/2/79+9W4cWNFRUUpKipKnTp1UteuXbVkyZJi\n",
       "rzMxMVGhlv/gAAAaGUlEQVTjxo0r9LKIiAglJycXe90DBw7U+++/7/x59+7datSokaZOnepcdvjw\n",
       "Yd111106ceLEJa9348aNioiIKPSywYMHn3d/7Nu3T3fddZcyMjLOu36nTp20cuVKxcXFaenSpRf9\n",
       "vVFRUZc1zqIU9hxdvHixBg8eXORtP/roI3Xv3l1hYWEKDg5W//799eOPP5bY2Mqjffv2aejQoRe8\n",
       "fO/evRo2bJiCg4PVuXNnde/eXR9//LHz8ry8PD3xxBN66KGH9OGHHzqXHz9+3Pn6ERwcLF9fX+dz\n",
       "7PXXXy/VOV2qAQMGaPfu3WU9jCuyf/9+3XPPPQWWJSQkqE2bNvr6668LfU5f7Lnev3//854/ZWns\n",
       "2LHq3LmzOnfurLvuukshISHOx9Xp06dL7Pf88ssvCgoKUteuXZWenl6sdZSX12bp7DZWmzZtFBUV\n",
       "pcjISIWFhelvf/ubTp06dRkzKuhSX0fLUuWyHgDO+vvf/67t27frnXfekYeHhyRpyZIl6tmzpxYu\n",
       "XKhvv/1WDRs2LONRXhkXF5fLWn6umTNnFvv3pqSk6Pfff9eKFSuKvY7L4eLiorlz5+qGG25wLps9\n",
       "e7bGjh2rBQsW/Clj+DNVr15dixcvdv584MAB9e3bV25uburQocNlr699+/Zq3759SQ7RKSAgQBs2\n",
       "bFDv3r0lSatXr1b79u2VmJioZ599VpL0zTffqHnz5rruuutKZQySVLduXfn5+Wnx4sUaNGiQc/l3\n",
       "332nEydOKDAwUEFBQUWu59z7vSRcynOxMFOmTNHmzZsVFxcnT09PSWfvx0GDBmnx4sXOZVeb/fv3\n",
       "a9euXRe87LHHHtOzzz6rKVOmSJIyMjIUGxur1NRUDRs2TA6HQ1999ZW+//77Avf99ddf79xQ2bhx\n",
       "o1577bUS/1tfqVmzZpX1EErEuff7ggUL9Pbbb2vOnDk6evToZa8rKSmpJId2xcaMGeP8d2BgoP7x\n",
       "j3+ocePGJf57Vq5cKT8/P7388svFXkd5eW3OFxYW5rz/jDF64oknNHfu3AKv11cbgqAcSE9P14IF\n",
       "C7Ru3boCD/TOnTtry5Yt6t+/vw4ePKivvvpK1apVkyT9+uuv6t27tw4ePKibb75ZU6dO1c0336z0\n",
       "9HS99tprSktLU05OjsLCwvT4449r//796tWrl+644w7t379fH3zwgW6++eY/dZ5F/afY06dP1/79\n",
       "+5WRkaEDBw7oxhtv1D//+U/VqlVL7du317Rp09SkSRMtWrRIc+bMkaurq2rWrKmJEyfK09NTq1ev\n",
       "1owZM5STk6Pq1atr+PDhuuGGGzR69GhlZGQoKipK8fHxqlq1aqnP89y55ubm6sCBA3J3d9eRI0fU\n",
       "rl07ff3116pevbpefPFF7dy5Ux988IEkqWPHjnrrrbe0YcMG51irVaumV155RXfccYfmzZtX6PL2\n",
       "7durQ4cO2rRpk06cOKG+ffsqOjq6VOd5IXXq1NHQoUM1a9Ys3XnnnXr11Vd16tQpZWRkyMfHR1On\n",
       "TlXVqlV199136/HHH1dSUpIOHjyo3r17q3fv3lq8eLFWrFiht99+W//97381evRoZWVl6bbbblNm\n",
       "Zqbz97z99ttatWqVTp8+rczMTA0fPrzIjeiAgABNnz7d+XNiYqJiY2M1bNgw7du3T3Xr1tXXX3+t\n",
       "Bx98UJK0Y8cOvfbaazpy5IgqVaqkvn37qnPnztq4caPGjRuna665RllZWXruueec68zIyNDzzz+v\n",
       "gwcPysvLS7/99luhY4mOjta4ceMKvMEsXLhQPXv2lIuLi0aOHKmGDRuqX79+iouL06pVq1SlShW5\n",
       "u7tr4sSJuvnmm9WoUSN98803cnd315tvvqmEhARVrlxZt956q1588UXddNNNeuyxx3TPPffo22+/\n",
       "1YEDB9SiRQtNmjSp0DEV9Rw9c+aMJk+erOTkZOXl5cnHx0dDhgzR+++/r5iYGA0aNKjAY3PkyJFa\n",
       "vXq1li5dqhMnTig1NVXXX3+9ateuraNHj2r8+PFatGiRKlWqpBUrVmjTpk365JNPNGvWLPXv318u\n",
       "Li56/fXXlZubq9zcXPn6+mr27Nl655139N133+nQoUPy9vZW/fr1L/raERERoTVr1ujo0aN68skn\n",
       "9e2332rLli2qUqWKZsyYoVq1al30tbNv37564IEH9MMPP+jYsWN65pln1LFjR73wwgvKyMjQgAED\n",
       "zttAnjlzpiIiIhQZGelcVrt2bf3zn/9UUFCQevXqpYEDByonJ0ddunRRXFyc6tWrd9H7P9+pU6f0\n",
       "0ksvae/evfr99991/fXXa+rUqapXr54eeeQRtWzZUps3b9aBAwd03333acKECVqxYoVmzJghFxcX\n",
       "GWOUmpqqkJAQjR8/Xm+++abWrFnjfC517dpVa9as0YkTJ5SRkaHTp0+rRo0aql27tqpVq6acnBz9\n",
       "+OOPatGihd555x1NnjxZH3zwgWrWrKlTp07phhtuUP/+/dWnT59Lmk958M4772jJkiWaP3++vLy8\n",
       "tHHjRudlmzZt0vDhw51hV9jy+Ph4SVLv3r31r3/9y/nBXnnxx/elhQsXatGiRcrJydGRI0c0ePBg\n",
       "de/eXRkZGRoxYoQziNq3b68nn3yy0MfclClT9O2332rhwoXKy8tTVlaWJk6cWKzxlafX5j/KzMxU\n",
       "ZmamatWqJens3ovLfV8712effaYpU6bonXfe0a233lqs+6tUGJS5FStWmIcffrjQyxITE02nTp3M\n",
       "888/b2bPnm2MMWbatGkmKCjI/P7778YYY4YMGWLeeustY4wxvXv3NqtXrzbGGJOdnW169+5tPv30\n",
       "U7Nv3z7j7e1tNm/eXPoTugBvb2/nmPN99tln5rHHHjPGnJ1Xhw4dzMmTJ40xxgwePNhMmzbNGGNM\n",
       "u3btzM8//2xSUlJM69atjcPhMMYY8+9//9u89NJLZvfu3SY8PNwcOXLEGGPMjh07TNu2bU1mZqbZ\n",
       "sGGDCQ8P/7Omaby9vU1ERITp1KmT8fPzM4GBgWbs2LHmt99+M8YY06dPH7NmzRpjjDEdO3Y0bdu2\n",
       "NadOnTI7duwwYWFhJjc319x1113m4MGDxhhjli5dahYuXHjB5fn3z4svvmiMMcbhcJjWrVub7du3\n",
       "l/pc9+3bZ+65557zlu/YscM0a9bMTJo0ySxbtswYY8yZM2dMRESE+fzzz40xZ++nDz/80BhjzM8/\n",
       "/2yaNm1qsrOzzSeffGIGDRpkjDGmc+fO5uOPPzbGGLN582bj4+NjNm7caPbv32/69OljsrOzjTHG\n",
       "/Oc//7nkv3FwcLBJSUkxR48eNX5+fsYYY1588UUzZ84cY4wxgYGBZufOnSYnJ8cEBQWZL774whhj\n",
       "THp6ugkICDDff/+92bBhg2ncuLFJS0szxpgCj7EhQ4aYN954wxhjTGpqqmnWrJlZvHjxeePIy8sz\n",
       "HTp0MBs3bjTGGHP8+HHTqlUrc/jwYWOMcT7n09LSTPPmzc3p06eNMca89957ZuXKlcYYYxo1amR+\n",
       "//13s2jRItOzZ0+TlZVljDn7XOrfv78xxphHH33UPPPMM8YYY06cOGH8/f3Nhg0bCr1v8h+7nTt3\n",
       "Np07dzaRkZHmwQcfdP49pk+fbiZNmuS8/pQpU8yAAQNMly5dLvjY7N27t9m5c6cJCgoyixYtMo0b\n",
       "NzY7duww9957r4mNjTXffPONadGihfHz8zNJSUmmW7duplWrVub777839913n1mwYIExxpiUlBTj\n",
       "4+Njli9fbqZNm2ZCQkJMXl6ec74Xe+2YOHGiMebs48THx8ds27bNGGNMTEyMmTlzpnOcF3vtzH/O\n",
       "rlixwrRr1+68v/sfhYeHO2/zR1FRUeaLL7644PPnXIX9jv/85z9mwoQJzp/HjBnj/Dk6OtrExsYa\n",
       "Y84+ptq2bWs2bdpU4PZffPGF6dixo/n999/Nnj17TL9+/ZzPpaVLl5rg4GDTpEkTM2bMGBMcHGxm\n",
       "zpxpHn30URMYGGiGDh1qjDHG39/fBAcHmxkzZphhw4Y5n89vvfWW6d27t/P5XJ7t27fP+TrVqFEj\n",
       "M2/ePOdl+ff7N998Yzp06OB8Pb3QcmPOPn/y34PKm/z3UGPOPi569uxpjh49aowxZtOmTaZly5bG\n",
       "GGPi4uLMa6+9Zowx5uTJk+aZZ54xJ0+evOhjburUqWb8+PFXPMby8to8bdo007p1a9O5c2cTERFh\n",
       "mjdvbiIiIszx48eNMcb8/e9/L/b72v/7f//PhIeHO7dhyhP2EJQTOTk5hS4/ffp0obvx77//frm7\n",
       "u0s6e9zvb7/9pszMTCUnJ+vYsWP65z//Kels2aakpKhp06aqXLmymjVrVnqTKEJh88jLy5Orq6vz\n",
       "51atWunaa6+VJDVu3Pi84zG/+eYb+fv7Oz99yS/vefPm6dChQ+rbt6/zU5DKlSsrNTW1VOZSlPxD\n",
       "hlJSUjRw4EDdc889uvHGGyVJQUFBWrt2rerVqycPDw81bNhQGzdu1LZt2xQcHKxKlSopJCREPXr0\n",
       "0IMPPqi2bdsqIiJCLi4uhS7P16tXL0mSh4eH/P39lZSUpDvvvLNM5u/i4qJrrrlGf/vb37R+/XrN\n",
       "mjVLu3fv1sGDB3Xy5Enn9QIDAyVJTZo00ZkzZwrsAThy5Ii2bdvm/IT13nvv1V/+8hdJZ/dCTJw4\n",
       "UUuXLtWePXv0/fffF7jtxfj7+2vjxo268cYb1bZtW0lSu3btNG/ePAUFBcnFxUW33Xabfv31V50+\n",
       "fdq516F27doKDg7WunXr1KpVK3l6ehZ6KMzXX3+t559/XpJUv359tW7d+oL3UY8ePbRo0SK1bNlS\n",
       "S5cu1QMPPKCaNWsWuJ6Hh4d8fHwUFRUlf39/BQQEqE2bNgWus27dOnXp0sW5B7F37956++23na8r\n",
       "7dq1kyS5ubmpQYMGFz0c4o+Hu+XvsZGkNWvW6Pjx485DI3JycuTi4qJq1ao5H5tt27ZVUlKSatSo\n",
       "oX/961/q0KGD1qxZo8OHDztv5+bmpvbt2yspKUmTJ0/WqVOnFBUVpeXLl8vhcOjOO+/Uli1b5OLi\n",
       "olmzZmn69Ok6ffq0jDHas2ePJMnX17fAa8rFXjuCg4Odf49atWo5D7+sV6+ejhw5UuRrZ5UqVfTA\n",
       "Aw84132ph5Nc6HX9zJkzxT48S5JCQ0PVoEEDzZ07V6mpqUpOTlarVq2cl+cfcnfdddepXr16Bca7\n",
       "efNmjR07Vv/+97/l7u4ud3d3jRs3zvlc+u6775SVlaU6deropptuUuvWreXr66vly5crLCxMO3fu\n",
       "1KxZs3Ts2DFlZWXJ09NTwcHBWr58ubZu3aqff/5ZNWvWdD6fS3uP7JXKzMzUf//7X73zzjt65pln\n",
       "dM8996hRo0aSJIfDocGDBys6OrrAa+mFlktF72UrD6677jq9+eabSkxM1O7du5WSkuI8Pj4gIECD\n",
       "Bw/W3r171aZNGw0fPlzXXnttkY+5klBeXpulgocM5ebm6vXXX9fTTz+td999V3/729+UlJR02e9r\n",
       "P/30k9avX6+RI0eWuz1IEicVlwu+vr7avXt3obuvNmzYoHvvvfe85VWqVHH+O/+NJTc3V5IUHx+v\n",
       "JUuWaMmSJVqwYIHzRJaqVauqUqWy+5PfeOON523g//bbb86wkc4ej56vsDdMV1fXAsuzs7O1c+dO\n",
       "5eXlqU2bNlq8eHGBuZfVeRf5bwo+Pj4aOXKkRo8erQMHDkiSOnTooC+//FLr169X27Zt1bZtW61f\n",
       "v16JiYnODZdJkyZp5syZatCggf71r38pJiam0OVPPvmk83eeG1Z5eXll+rf+6aef1LBhQz377LNa\n",
       "uHChbrnlFvXr1++841fzN2Dznftm6uLi4jy8IV/lymc/w/jll1/Us2dPnTx5Un5+fho4cOAlvxH7\n",
       "+/srOTlZq1evdu5+bt26tX755Rd99dVXzg2/vLy8825rjNGZM2ckybnx+Ud/fNzmj7kwXbt21Zdf\n",
       "fqkTJ07oo48+0qOPPlro+ubOnauJEyeqZs2amjBhgsaPH1/gOn8ca/4hNvn3ybnPq/x5XMjFLsvN\n",
       "zdXo0aOdz7GPPvpIU6dO1c6dOzV69GjNnDlTf/nLX1S7dm15eXkpJCRE8fHx2rFjhypXrqzhw4fL\n",
       "1dVVxhjdcMMNysnJUWJiourWrasjR45o9erVatCggYKDg5WXl6dq1arJx8dHo0aN0rx589S8eXPn\n",
       "G6mbm1uBsV3stePcjdLC/h5FvXb+8fX2Uh5r9957rzZs2HDe8vT0dO3bt0933313keu4kLlz5+qF\n",
       "F16Qm5ubOnXqpJCQkAJjOvd5de54f/31V+c5DQ0aNJAk/fzzz4qOjtapU6fk7++vAQMGFFhH9erV\n",
       "netYuXKltm3bpltuuUVubm667bbbtGXLFj3xxBNycXFRUFCQevTo4fx9FWHj+JprrtGMGTPk7++v\n",
       "QYMGKSYmRseOHZN09rHy3nvvafHixfrpp5+ct7nQ8oriwIED6tKli9LT09WyZUs9/fTTzst8fX21\n",
       "atUqdevWTfv27VPXrl31448/FvmYKwnl6bX5XK6ururWrZs2b94sScV+X6tRo4beffddTZs2zbk9\n",
       "UJ4QBOWAh4eHevfurWHDhhU4Q//jjz/W559/roEDB8rV1dX5YL+Q6667Tr6+vnr33XclSceOHVN0\n",
       "dLRWrVolqexfnAMCAjR37lznOI4eParFixc7n+SX4r777tNXX32lQ4cOSTr7zUyTJ09WmzZtlJSU\n",
       "pJ07d0qSvvzyS0VGRio7O7vkJ3KZwsLCdO+99zq/OcfDw0M1a9ZUfHy8/Pz8dP/99+vzzz/XkSNH\n",
       "1KhRI/3+++968MEH5e7urt69e+uZZ57Rtm3bCl2+detW5+/J/0aaAwcO6KuvvlJAQMCfMr8/Pq52\n",
       "7dqlGTNmqF+/fkpKSlJMTIzzzeOHH35wbnwVtZ4bbrhBTZo00UcffSRJ2rJli7Zv3y5JSk5OVtOm\n",
       "TdW3b1+1bNlSK1euLPRNojCtW7dWSkqKNm3aJD8/P0lnN3qaNGmiDz/80PlGdNttt6lKlSpauXKl\n",
       "pLMbcitWrHB+cnUhAQEBzuOJDxw4UOhGYT53d3e1a9dO06ZNk6ura6EbiVu3blV4eLjuuOMOPf74\n",
       "4+rbt6/z755/n/n7++uTTz5xfhI1d+5ctWzZssCGbEnw9/fXhx9+qDNnzigvL0+jR4/W+++/r+7d\n",
       "u8vPz0/Z2dnOx+aWLVv0zTffKCcnRy+++KKuv/56vfvuuzpz5ozzvvTz89PkyZPVqVMnbdq0SUeP\n",
       "HtWePXvUsWNHtW7dWg6HQ5GRkQoJCdHGjRuVnJxcot+Oku9yXzvzf3Z1db3gXoAnnnhCn332WYFv\n",
       "MXE4HIqNjVWvXr2cxyMX53U5KSlJDz/8sLp06aIGDRpozZo1F3xe5cvIyNDjjz+ukSNHFviQaePG\n",
       "jWrWrJn69OmjFi1a6Isvvrjguvbu3atmzZopJCRE0tnjuHfs2OH8pNbb21srV64sEKMVQf6HJ48/\n",
       "/rjuvPNOPfvss8rLy9PNN9+sZs2aacSIEXruueec7ycXWl65cuULPh7Kk59++km1a9fWoEGD1LZt\n",
       "WyUmJjpfP/M/dAoKCtKYMWN0++23KzU1tViPuctVnl6b/+jzzz93vj4X932tQYMGuu+++/Too49q\n",
       "+PDhl/y7/ywcMlROPPvss/r44481ZMgQnT59WqdPn9bdd9+thQsXysvLSwEBAXrttdeKXM/kyZP1\n",
       "2muvKSIiQjk5OYqIiFB4eLj2799/RbuoS8KoUaM0ceJEhYeHq3LlyjLGKCoqSp07dy7ytvljb9iw\n",
       "oYYPH+484bBWrVoaP368atWqpVdffVXDhg2TdPaNesaMGed9MvpnKOx+HjNmjCIjI5WUlKS2bduq\n",
       "Q4cOeu+995yfLFSvXt25d6BmzZoaMmSI+vTpo2rVqqlKlSoaN27cBZfn27dvn7p06aLTp09rzJgx\n",
       "f9rJSqdPn1ZUVJQkOQ8fiY2N1QMPPKBnn31WMTExcnd31zXXXKNWrVo5D/n44/1U2P32j3/8QyNH\n",
       "jtT8+fPVoEED3XHHHZKk8PBwff755woLC1PVqlXVunVrHTlyRKdOnbrgp0P5qlWrpltvvVW5ubkF\n",
       "TuJ/4IEH9Prrrzt3g1euXFlvvvmmxo4dq7i4OOXl5empp55Sq1atCpxw+EcvvPCCRo0apbCwMHl6\n",
       "esrHx+ei43nkkUfUo0eP8z71z9eoUSOFhISoS5cuuvbaa3XNNdc4d2Xn32cPP/ywHA6HunXrJmOM\n",
       "6tev7/x6yku5ny/lMkkaMmSIJk2apKioKOdJxSNGjJCbm5tOnDihRx55xHldLy8vBQcH6/bbb1d4\n",
       "eLiqVq2q5cuXq3LlyoqNjdVTTz2lhg0bKjo6WsHBwdq2bZuks7v/PTw85OHhoW7duunpp5+Wq6ur\n",
       "XF1d1bx5c6WlpV1W6Fzq697lvHbm/3znnXeqUqVK6t69uxYuXFjgOp6enoqPj9fUqVP19ttvq0qV\n",
       "Kqpatap69uypbt26Xfb4ztW/f3+99NJLzhOymzZt6vww5EJjfeONN3T06FHNnj3b+a1tderU0auv\n",
       "vqqVK1cqPDxcVapUUevWrXX8+PECe27z3XfffUpMTNTDDz+sY8eO6Z577lG9evWUlJQkY4wGDhyo\n",
       "++67T6tWrSrz95tL9cdxTpw4UV26dNEbb7zhXNa5c2d9/vnnmjhxojOG/rj8pZdeUlBQkB555BG9\n",
       "9dZbzsMby4tz5xkQEKBPPvlEHTt2lJubm3x9fVWjRg3t3btXffv21fPPP6+IiAhVqVJFTZo0UUhI\n",
       "iDw9PS/4mCsp5em1OSEhwblHIDs7W/Xr19ff//53SdKwYcOu6H3tiSee0OrVqzVr1iznHrnywMVU\n",
       "pIwHUKhzv4UJAADgcnDIEHAVqCifxgEAgPKHPQQAAACAxdhDgP/ffh0IAAAAAAjytx7ksggAgDEh\n",
       "AACAMSEAAIAxIQAAgDEhAACAMSEAAICxACo8e+YEecdKAAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1037aa890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#for funders\n",
    "functional = df_new[df_new['status_group']=='functional']['funder'].tolist()\n",
    "non_functional = df_new[df_new['status_group']=='non functional']['funder'].tolist()\n",
    "needs_repair = df_new[df_new['status_group']=='functional needs repair']['funder'].tolist()\n",
    "\n",
    "plt.rc('xtick', labelsize=12) \n",
    "plt.rc('ytick', labelsize=12)\n",
    "\n",
    "categories = pd.Series(df_new.funder.values.ravel()).unique()\n",
    "value_freq_funct = []\n",
    "value_freq_nonf = []\n",
    "value_freq_repair = []\n",
    "categories_num = range(1,len(categories)+1)\n",
    "for value in categories:\n",
    "    value_freq_funct.append(functional.count(value))\n",
    "    value_freq_nonf.append(non_functional.count(value))\n",
    "    value_freq_repair.append(needs_repair.count(value))\n",
    "\n",
    "plt.bar(categories_num,value_freq_funct,align='center',color='g')\n",
    "plt.bar(categories_num,value_freq_nonf,align='center',color='r')\n",
    "plt.bar(categories_num,value_freq_repair,align='center',color='b')\n",
    "plt.xticks(categories_num, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Other', 'Unicef', 'Rwssp', 'Danida', 'World Vision', 'Hesawa',\n",
       "       'Government Of Tanzania', nan, 'Kkkt', 'Tasaf', 'World Bank'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(df.funder.values.ravel()).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are working with a lot of categorical feature data, we first need to turn the multiclass feature variables into indicators for each of the possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>population</th>\n",
       "      <th>date_recorded_offset_days</th>\n",
       "      <th>status_group</th>\n",
       "      <th>funder_Danida</th>\n",
       "      <th>funder_Government Of Tanzania</th>\n",
       "      <th>funder_Hesawa</th>\n",
       "      <th>funder_Kkkt</th>\n",
       "      <th>funder_Other</th>\n",
       "      <th>...</th>\n",
       "      <th>date_recorded_month_Dec</th>\n",
       "      <th>date_recorded_month_Feb</th>\n",
       "      <th>date_recorded_month_Jan</th>\n",
       "      <th>date_recorded_month_Jul</th>\n",
       "      <th>date_recorded_month_Jun</th>\n",
       "      <th>date_recorded_month_Mar</th>\n",
       "      <th>date_recorded_month_May</th>\n",
       "      <th>date_recorded_month_Nov</th>\n",
       "      <th>date_recorded_month_Oct</th>\n",
       "      <th>date_recorded_month_Sep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.831495</td>\n",
       "      <td>1.042939</td>\n",
       "      <td>-0.148715</td>\n",
       "      <td>1.135927</td>\n",
       "      <td>functional</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.101290</td>\n",
       "      <td>1.055942</td>\n",
       "      <td>0.205933</td>\n",
       "      <td>-1.021636</td>\n",
       "      <td>functional</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.093236</td>\n",
       "      <td>0.025834</td>\n",
       "      <td>0.143714</td>\n",
       "      <td>-0.994778</td>\n",
       "      <td>functional</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.101290</td>\n",
       "      <td>-0.585296</td>\n",
       "      <td>-0.254488</td>\n",
       "      <td>-0.911221</td>\n",
       "      <td>non functional</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.101290</td>\n",
       "      <td>-0.965266</td>\n",
       "      <td>-0.374778</td>\n",
       "      <td>0.774841</td>\n",
       "      <td>functional</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh  gps_height  population  date_recorded_offset_days  \\\n",
       "0    1.831495    1.042939   -0.148715                   1.135927   \n",
       "1   -0.101290    1.055942    0.205933                  -1.021636   \n",
       "2   -0.093236    0.025834    0.143714                  -0.994778   \n",
       "3   -0.101290   -0.585296   -0.254488                  -0.911221   \n",
       "4   -0.101290   -0.965266   -0.374778                   0.774841   \n",
       "\n",
       "     status_group  funder_Danida  funder_Government Of Tanzania  \\\n",
       "0      functional              0                              0   \n",
       "1      functional              0                              0   \n",
       "2      functional              0                              0   \n",
       "3  non functional              0                              0   \n",
       "4      functional              0                              0   \n",
       "\n",
       "   funder_Hesawa  funder_Kkkt  funder_Other           ...             \\\n",
       "0              0            0             1           ...              \n",
       "1              0            0             1           ...              \n",
       "2              0            0             1           ...              \n",
       "3              0            0             0           ...              \n",
       "4              0            0             1           ...              \n",
       "\n",
       "   date_recorded_month_Dec  date_recorded_month_Feb  date_recorded_month_Jan  \\\n",
       "0                        0                        0                        0   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        1                        0   \n",
       "3                        0                        0                        1   \n",
       "4                        0                        0                        0   \n",
       "\n",
       "   date_recorded_month_Jul  date_recorded_month_Jun  date_recorded_month_Mar  \\\n",
       "0                        0                        0                        1   \n",
       "1                        0                        0                        1   \n",
       "2                        0                        0                        0   \n",
       "3                        0                        0                        0   \n",
       "4                        1                        0                        0   \n",
       "\n",
       "   date_recorded_month_May  date_recorded_month_Nov  date_recorded_month_Oct  \\\n",
       "0                        0                        0                        0   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        0                        0   \n",
       "3                        0                        0                        0   \n",
       "4                        0                        0                        0   \n",
       "\n",
       "   date_recorded_month_Sep  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_formatted includes all the data from df_new, with the categorical variables as indicators\n",
    "df_formatted = pd.get_dummies(df_new, columns=CATEGORICAL)\n",
    "df_formatted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#feat_train and lab_train analogous to Xtrain and ytrain\n",
    "feat_train = df_formatted[mask].drop('status_group',axis=1)\n",
    "lab_train = pd.DataFrame(df_formatted[mask].status_group)\n",
    "##feat_test and lab_test analogous to Xtrain and ytrain\n",
    "feat_test = df_formatted[~mask].drop('status_group',axis=1)\n",
    "lab_test = pd.DataFrame(df_formatted[~mask].status_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Naive Bayes\n",
    "\n",
    "We begin with Naive Bayes to set up a baseline classifier. While the probabilities may not be too well calibrated, the relative order of of the probabilities across the labels is typically correct.\n",
    "\n",
    "Because we have a combination of categorical and continuous predictors, we first independently fit a Gaussian Naive Bayes model on the continuous data and a bernoulli Naive Bayes model on the categorical part. \n",
    "\n",
    "####TO DECIDE\n",
    "\n",
    "Then we __________ transform the entire dataset by taking the class assignment probabilities (with the predict_proba() method) as the new features: np.hstack((multinomial_probas, gaussian_probas)) and then refit a new model (e.g. a new gaussian NB) on these new features.\n",
    "\n",
    "calibrate (show plot)\n",
    "log -> sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "#separate categorical and continuous\n",
    "cont_feat_train = feat_train[STANDARDIZABLE].values\n",
    "cat_feat_train = feat_train.drop(STANDARDIZABLE,axis=1).values\n",
    "cont_feat_test = feat_test[STANDARDIZABLE].values\n",
    "cat_feat_test = feat_test.drop(STANDARDIZABLE,axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frac of correctly labeled points 0.425869809203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1025,   71,  319],\n",
       "       [   0,    0,    0],\n",
       "       [8617, 1224, 6564]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the continuous variables to a Gaussian Naive Bayes\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(cont_feat_train, lab_train)\n",
    "print \"Frac of correctly labeled points\",float((lab_test.values.transpose().tolist() == gnb_clf.predict(cont_feat_test)).sum())/lab_test.shape[0]\n",
    "confusion_matrix(gnb_clf.predict(cont_feat_test),lab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frac of correctly labeled points 0.655274971942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7042,  545, 2125],\n",
       "       [ 955,  471,  594],\n",
       "       [1645,  279, 4164]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the categorical variables to a Bernoulli Naive Bayes\n",
    "bnb_clf = BernoulliNB()\n",
    "bnb_clf.fit(cat_feat_train, lab_train)\n",
    "\n",
    "print \"Frac of correctly labeled points\",float((lab_test.values.transpose().tolist() == bnb_clf.predict(cat_feat_test)).sum())/lab_test.shape[0]\n",
    "confusion_matrix(bnb_clf.predict(cat_feat_test),lab_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a higher accuracy, yet we can still do better. We know that the Bernoulli model factors into account the nonoccurence of the different features. As a result, it puts more weight on the features that have many values associated, not factoring in inherent dependence and mutually exclusive nature of these feature. For example, if a row has a 1 for funder World Bank, it will have a 0 for all the other funders, and the Bernoulli model will take into account the 1 and all the 0s, despite them being very dependent.\n",
    "\n",
    "We instead fit the model for categorical feature variables to a Multinomial Naive Bayes. The model performs better, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frac of correctly labeled points 0.677665544332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7590,  647, 2425],\n",
       "       [ 640,  384,  356],\n",
       "       [1412,  264, 4102]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the categorical variables to a Multinomial Naive Bayes\n",
    "mnb_clf = MultinomialNB()\n",
    "mnb_clf.fit(cat_feat_train, lab_train)\n",
    "\n",
    "print \"Frac of correctly labeled points\",float((lab_test.values.transpose().tolist() == mnb_clf.predict(cat_feat_test)).sum())/lab_test.shape[0]\n",
    "confusion_matrix(mnb_clf.predict(cat_feat_test),lab_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes does not work well with highly correlated features because the conditional independence assumption of Naive Bayes overinflates the importance of these correlated features by in effect counting them twice. Thus, we remove some of the redundant features, particularly the more broad feature in the nesting structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_df_new = df_new.drop(['management_group','source_class','extraction_type_class'], axis=1)\n",
    "small_df_formatted = pd.get_dummies(small_df_new, columns=list(set(CATEGORICAL).difference(['management_group','source_class','extraction_type_class'])))\n",
    "\n",
    "\n",
    "reduced_feat_train = small_df_formatted[mask].drop('status_group',axis=1)\n",
    "reduced_feat_test = small_df_formatted[~mask].drop('status_group',axis=1)\n",
    "\n",
    "cont_feat_train1 = reduced_feat_train[STANDARDIZABLE].values\n",
    "cat_feat_train1 = reduced_feat_train.drop(STANDARDIZABLE,axis=1).values\n",
    "cont_feat_test1 = reduced_feat_test[STANDARDIZABLE].values\n",
    "cat_feat_test1 = reduced_feat_test.drop(STANDARDIZABLE,axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frac of correctly labeled points 0.425869809203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1025,   71,  319],\n",
       "       [   0,    0,    0],\n",
       "       [8617, 1224, 6564]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_clf1 = GaussianNB()\n",
    "gnb_clf1.fit(cont_feat_train1, lab_train)\n",
    "print \"Frac of correctly labeled points\",float((lab_test.values.transpose().tolist() == gnb_clf1.predict(cont_feat_test1)).sum())/lab_test.shape[0]\n",
    "confusion_matrix(gnb_clf1.predict(cont_feat_test1),lab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frac of correctly labeled points 0.669977553311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7170,  568, 2172],\n",
       "       [ 730,  427,  369],\n",
       "       [1742,  300, 4342]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the categorical variables to a Bernoulli Naive Bayes\n",
    "bnb_clf1 = BernoulliNB()\n",
    "bnb_clf1.fit(cat_feat_train1, lab_train)\n",
    "\n",
    "print \"Frac of correctly labeled points\",float((lab_test.values.transpose().tolist() == bnb_clf1.predict(cat_feat_test1)).sum())/lab_test.shape[0]\n",
    "confusion_matrix(bnb_clf1.predict(cat_feat_test1),lab_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a higher accuracy, yet we can still do better. We know that the Bernoulli model factors into account the nonoccurence of the different features. As a result, it puts more weight on the features that have many values associated, not factoring in inherent dependence and mutually exclusive nature of these feature. For example, if a row has a 1 for funder World Bank, it will have a 0 for all the other funders, and the Bernoulli model will take into account the 1 and all the 0s, despite them being very dependent.\n",
    "\n",
    "We instead fit the model for categorical feature variables to a Multinomial Naive Bayes. The model performs better, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frac of correctly labeled points 0.688496071829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7673,  673, 2388],\n",
       "       [ 489,  328,  227],\n",
       "       [1480,  294, 4268]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the categorical variables to a Multinomial Naive Bayes\n",
    "mnb_clf1 = MultinomialNB()\n",
    "mnb_clf1.fit(cat_feat_train1, lab_train)\n",
    "\n",
    "print \"Frac of correctly labeled points\",float((lab_test.values.transpose().tolist() == mnb_clf1.predict(cat_feat_test1)).sum())/lab_test.shape[0]\n",
    "confusion_matrix(mnb_clf1.predict(cat_feat_test1),lab_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we split the categorical and quantitative features, we did not get to use all our features. To allow for that, we bucket our quantitative features to turn them into categorical ones. We bucket them how we deem appropriate according to the graphs above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#turn quantitative variables to categorical ones\n",
    "df_allcat = small_df_new.copy()\n",
    "\n",
    "df_allcat.ix[df_allcat.amount_tsh>40, 'amount_tsh'] = \"High\"\n",
    "df_allcat.ix[(df_allcat.amount_tsh>10) & (df_new.amount_tsh<=40), 'amount_tsh'] = \"Medium\"\n",
    "df_allcat.ix[df_allcat.amount_tsh<=10, 'amount_tsh'] = \"Low\"\n",
    "\n",
    "df_allcat.ix[df_allcat.gps_height>0, 'gps_height'] = \"Above avg\"\n",
    "df_allcat.ix[df_allcat.gps_height<=0, 'gps_height'] = \"Below avg\"\n",
    "\n",
    "df_allcat.ix[df_allcat.date_recorded_offset_days>0, 'date_recorded_offset_days'] = \"Above avg\"\n",
    "df_allcat.ix[df_allcat.date_recorded_offset_days<=0, 'date_recorded_offset_days'] = \"Below avg\"\n",
    "\n",
    "df_allcat.ix[df_allcat.population>10, 'population'] = \"High\"\n",
    "df_allcat.ix[(df_allcat.population<10)&(df_allcat.population>0), 'population'] = \"Medium\"\n",
    "df_allcat.ix[df_allcat.population<=0, 'population'] = \"Low\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_allcat = df_allcat.drop('status_group',axis=1)\n",
    "df_allcat_formatted = pd.get_dummies(df_allcat)\n",
    "\n",
    "new_feat_train = df_allcat_formatted[mask]\n",
    "new_feat_test = df_allcat_formatted[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This performs approximately the same with our previous Multinomial Bayes model on just the categorical features alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Frac of correctly labeled points 0.682940516274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7597,  668, 2392],\n",
       "       [ 493,  333,  251],\n",
       "       [1552,  294, 4240]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit all variables to a Multinomial Naive Bayes\n",
    "mnb_clf2 = MultinomialNB()\n",
    "mnb_clf2.fit(new_feat_train, lab_train)\n",
    "\n",
    "print \"Frac of correctly labeled points\",float((lab_test.values.transpose().tolist() == mnb_clf2.predict(new_feat_test)).sum())/lab_test.shape[0]\n",
    "confusion_matrix(mnb_clf2.predict(new_feat_test),lab_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plat a calibration plot for our full Multinomial NB model, as well as the Multinomial NB on the reduced list of categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: make it work for ytest being categorical\n",
    "def calibration_plot(clf, xtest, ytest):\n",
    "    prob = clf.predict_proba(xtest)[:, 1]\n",
    "    outcome = ytest\n",
    "    data = pd.DataFrame(dict(prob=prob, outcome=outcome))\n",
    "\n",
    "    #group outcomes into bins of similar probability\n",
    "    bins = np.linspace(0, 1, 20)\n",
    "    cuts = pd.cut(prob, bins)\n",
    "    binwidth = bins[1] - bins[0]\n",
    "    \n",
    "    #freshness ratio and number of examples in each bin\n",
    "    cal = data.groupby(cuts).outcome.agg(['mean', 'count'])\n",
    "    cal['pmid'] = (bins[:-1] + bins[1:]) / 2\n",
    "    cal['sig'] = np.sqrt(cal.pmid * (1 - cal.pmid) / cal['count'])\n",
    "        \n",
    "    #the calibration plot\n",
    "    ax = plt.subplot2grid((3, 1), (0, 0), rowspan=2)\n",
    "    p = plt.errorbar(cal.pmid, cal['mean'], cal['sig'])\n",
    "    plt.plot(cal.pmid, cal.pmid, linestyle='--', lw=1, color='k')\n",
    "    plt.ylabel(\"Empirical Fraction\")\n",
    "\n",
    "    \n",
    "    #the distribution of P(fresh)\n",
    "    ax = plt.subplot2grid((3, 1), (2, 0), sharex=ax)\n",
    "    #calsum = cal['count'].sum()\n",
    "    plt.bar(left=cal.pmid - binwidth / 2, height=cal['count'],\n",
    "            width=.95 * (bins[1] - bins[0]),\n",
    "            fc=p[0].get_color())\n",
    "    plt.xlabel(\"Classifier Probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calibration_plot(mnb_clf1, cont_feat_test1, lab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calibration_plot(mnb_clf2, new_feat_test, lab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17820, 139)\n",
      "[[ 0.29493591  0.07536548  0.62969861  0.75753708  0.06756535  0.17489756]\n",
      " [ 0.21525895  0.05865076  0.72609029  0.57245036  0.30492416  0.12262548]\n",
      " [ 0.19871927  0.07104323  0.73023751  0.70299508  0.03008168  0.26692324]\n",
      " ..., \n",
      " [ 0.26510723  0.07571938  0.65917339  0.99126605  0.00300007  0.00573388]\n",
      " [ 0.22146002  0.05497675  0.72356323  0.88664278  0.05290528  0.06045194]\n",
      " [ 0.22398112  0.05357364  0.72244524  0.71583435  0.02800989  0.25615576]]\n",
      "***\n",
      "[[ 0.75753708  0.06756535  0.17489756]\n",
      " [ 0.57245036  0.30492416  0.12262548]\n",
      " [ 0.70299508  0.03008168  0.26692324]\n",
      " ..., \n",
      " [ 0.99126605  0.00300007  0.00573388]\n",
      " [ 0.88664278  0.05290528  0.06045194]\n",
      " [ 0.71583435  0.02800989  0.25615576]]\n",
      "***\n",
      "(41580, 135)\n"
     ]
    }
   ],
   "source": [
    "# #TODO\n",
    "# #optimize with Fisher's method\n",
    "# #combine for mixed Bayes?\n",
    "\n",
    "# #find the probabilities for the Multinomial and Gaussian Naive Bayes\n",
    "# gnb_probs = gnb_clf1.predict_proba(cont_feat_train1)\n",
    "# mnb_probs = mnb_clf1.predict_proba(cat_feat_train1)\n",
    "\n",
    "# #combine\n",
    "# feat_probs = np.hstack((gnb_probs, mnb_probs))\n",
    "\n",
    "# nb_clf = GaussianNB()\n",
    "# #nb_clf.fit(feat_probs, lab_train)\n",
    "# feat_probs = nb_clf.predict_proba(feat_test)\n",
    "# print reduced_feat_test.shape\n",
    "# print feat_probs\n",
    "# print '***'\n",
    "# print mnb_probs\n",
    "# print '***'\n",
    "# print cat_feat_train1.shape\n",
    "# #don't know how to change the inputs to probabilities \n",
    "# # print \"Frac of mislabeled points\",float((lab_test.values.transpose().tolist() != nb_clf.predict(reduced_feat_test)).sum())/lab_test.shape[0]\n",
    "# # confusion_matrix(nb_clf.predict(reduced_feat_test),lab_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one problem with this above approach, however, is that .predict_proba(X) method will return posteriors normalized over all classes. What we want is the unnormalized probabilities so that we can multiply them together. However, if they are normalized differently (which they are, since they are normalized for the classes), the product of such probabilities is not very reliable.http://stats.stackexchange.com/questions/93928/naive-bayes-continuous-and-categorical-predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since mixing the Gaussian and Multinomial models is rather difficult, we move to a model that can more easily include both: the SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##SVM\n",
    "\n",
    "Add Cindy's code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Optimizing the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following models, we have some hyperparameters to optimize for. Thus, now we write two functions: cv_optimize() use GridSearchCV to choose the best regularization hyperparameter for the model, and do_classify() to print out the model fit on the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_optimize(clf, parameters, X, y, n_jobs=1, n_folds=5, score_func=None):\n",
    "    if score_func:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, n_jobs=n_jobs, scoring=score_func)\n",
    "    else:\n",
    "        gs = GridSearchCV(clf, param_grid=parameters, n_jobs=n_jobs, cv=n_folds)\n",
    "    gs.fit(X, y)\n",
    "    print \"BEST\", gs.best_params_, gs.best_score_, gs.grid_scores_\n",
    "    best = gs.best_estimator_\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_classify(clf, parameters, indf, featurenames, targetname, target1val, mask=None, reuse_split=None, score_func=None, n_folds=5, n_jobs=1):\n",
    "    subdf=indf[featurenames]\n",
    "    X=subdf.values\n",
    "    y=indf[targetname].values\n",
    "    if mask !=None:\n",
    "        print \"using mask\"\n",
    "        Xtrain, Xtest, ytrain, ytest = X[mask], X[~mask], y[mask], y[~mask]\n",
    "    if reuse_split !=None:\n",
    "        print \"using reuse split\"\n",
    "        Xtrain, Xtest, ytrain, ytest = reuse_split['Xtrain'], reuse_split['Xtest'], reuse_split['ytrain'], reuse_split['ytest']\n",
    "    if parameters:\n",
    "        clf = cv_optimize(clf, parameters, Xtrain, ytrain, n_jobs=n_jobs, n_folds=n_folds, score_func=score_func)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print \"############# based on standard predict ################\"\n",
    "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "    print confusion_matrix(ytest, clf.predict(Xtest))\n",
    "    print \"########################################################\"\n",
    "    return clf, Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we use the score() function in to measure the accuracy of our model's predictions. Other model evaluation/comparison measures we could consider are the balanced F-score (sklearn.metrics.f1_score()), the Kappa Statistic, Confusion Matrix, Hamming Loss, and Zero One loss. More options can be found here: http://scikit-learn.org/stable/modules/model_evaluation.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Regression\n",
    "\n",
    "Because we have a categorical outcome variable with more than one outcome, we conduct a multinomial logistic regression with LASSO (specifically, L2) regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We optimize for our best C and thn fit a multinomial logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_cols=list(df_formatted.columns)\n",
    "feat_cols.remove(u'status_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 6.91 µs\n",
      "using mask\n",
      "BEST {'C': 0.1} 0.733645983646 [mean: 0.71878, std: 0.00350, params: {'C': 0.001}, mean: 0.72905, std: 0.00325, params: {'C': 0.01}, mean: 0.73365, std: 0.00387, params: {'C': 0.1}, mean: 0.73343, std: 0.00336, params: {'C': 1.0}, mean: 0.73360, std: 0.00307, params: {'C': 10.0}, mean: 0.73350, std: 0.00308, params: {'C': 100.0}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.74\n",
      "Accuracy on test data:     0.73\n",
      "[[8683   40  919]\n",
      " [ 988   81  226]\n",
      " [2557   30 4296]]\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "clfmlr, Xtrain, ytrain, Xtest, ytest = do_classify(LogisticRegression(penalty=\"l2\",solver='newton-cg', multi_class='multinomial'), \n",
    "                                                   {\"C\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}, df_formatted,feat_cols, u'status_group',1, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the fitted model itself and interpret the coefficients. #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.05667989, -1.52646751,  0.46978761])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfmlr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.70633762e-02,  -1.28591247e-02,   4.70359154e-02,\n",
       "          2.64049469e-02,   6.68547898e-02,  -1.05230087e-01,\n",
       "         -3.82488940e-01,  -1.22267564e-02,   6.97632103e-02,\n",
       "          1.67253862e-01,  -6.75761152e-02,  -8.59987093e-02,\n",
       "         -2.68092128e-01,  -5.81354652e-02,   2.10960246e-01,\n",
       "          3.21800677e-01,  -1.33891583e-01,  -1.20735350e-01,\n",
       "         -5.51591869e-01,   2.51552801e-01,  -4.26499003e-01,\n",
       "         -6.01811569e-03,  -5.19905415e-01,  -2.22513792e-01,\n",
       "          7.40570710e-02,   4.02198779e-01,  -2.26100645e-01,\n",
       "          7.97436638e-02,  -1.09628868e-01,   1.86948414e-02,\n",
       "          2.15374182e-02,  -2.29650100e-01,  -3.08521493e-02,\n",
       "          3.04002159e-01,   1.44965903e-01,  -1.85458047e-01,\n",
       "          5.79828641e-01,   7.74782519e-03,  -3.80892067e-01,\n",
       "         -1.01381877e-01,  -9.88166107e-02,   1.76858267e-01,\n",
       "         -1.23660961e-01,  -1.08374544e-01,  -1.07879753e-01,\n",
       "         -3.80985565e-01,   1.75459288e-01,   3.51387406e-02,\n",
       "         -2.60963866e-01,   2.14899043e-01,  -1.32688484e-01,\n",
       "          8.71103958e-04,  -2.15567639e-02,   2.62887581e-01,\n",
       "         -3.69333096e-01,   6.59835871e-03,  -1.44566321e-01,\n",
       "          2.52913253e-01,  -2.41223115e-01,  -2.03614838e-01,\n",
       "         -9.77266708e-02,   1.30594945e-01,   2.86376639e-02,\n",
       "          7.11811495e-02,  -2.21395704e-01,   4.20894430e-01,\n",
       "         -1.16123523e-01,   2.15131137e-02,   1.49274416e-01,\n",
       "          3.50275422e-01,  -2.84920425e-02,   2.25664259e-01,\n",
       "         -1.62310998e-01,  -3.31124981e-02,   2.79485611e-01,\n",
       "         -9.18456138e-02,  -2.51781037e-01,  -1.20700287e-01,\n",
       "          1.43747118e-01,  -4.25367503e-02,  -1.14916736e-01,\n",
       "         -1.53476435e-01,  -2.84920425e-02,   3.26416520e-01,\n",
       "         -1.53812785e-01,  -9.18456138e-02,   1.43747118e-01,\n",
       "         -4.25367503e-02,  -1.53476435e-01,  -4.06535456e-01,\n",
       "          1.71180941e-01,  -1.00703610e-01,  -3.30884995e-03,\n",
       "          6.17722992e-01,  -1.94849049e-02,   2.44901643e-02,\n",
       "         -1.55124672e-01,  -1.38301983e-01,   3.17756117e-02,\n",
       "         -1.65477680e-01,   1.43767458e-01,   5.34006486e-02,\n",
       "          7.04773311e-02,  -3.30884995e-03,   2.44901643e-02,\n",
       "         -1.45059282e-01,   1.64539139e-01,   4.27868644e-02,\n",
       "         -3.07410064e-01,   2.80860413e-02,  -1.34922484e-01,\n",
       "          3.17556188e-01,  -1.10635673e-01,  -5.36706817e-02,\n",
       "          2.87426883e-01,  -1.23384235e-01,   5.79741445e-01,\n",
       "         -7.51228296e-02,  -4.00497442e-01,   2.65845404e-03,\n",
       "         -2.17151581e-01,  -1.43137597e+00,   5.22256805e-01,\n",
       "          2.16540820e-01,   3.90140495e-01,   3.02437865e-01,\n",
       "         -8.78888578e-02,  -1.64426631e-01,   1.87195115e-01,\n",
       "          3.36002097e-01,  -2.42217655e-01,  -1.17575090e-01,\n",
       "          8.89110345e-02,  -1.16552913e-01,  -7.06421902e-02,\n",
       "          1.87195115e-01,   3.17831862e-01,  -7.08752070e-02,\n",
       "          1.62477698e-01,  -2.45569021e-02,   4.16764953e-01,\n",
       "         -8.01642391e-01,  -1.55093515e-01,   8.37211240e-02,\n",
       "          2.61778459e-01,  -4.48456804e-02,  -1.77946611e-01,\n",
       "         -2.47297929e-02,   1.95644915e-02,   7.30194996e-02,\n",
       "         -4.36735072e-02,  -6.76203453e-02,  -5.98430072e-02,\n",
       "          1.35668897e-01],\n",
       "       [  3.01975523e-02,   1.63039618e-01,   1.75022598e-02,\n",
       "         -9.21368156e-02,  -3.73041706e-01,  -4.40269083e-01,\n",
       "          2.67545094e-01,  -4.41010581e-01,  -2.73149899e-01,\n",
       "         -3.09843577e-01,  -1.25802253e-01,   5.22270394e-02,\n",
       "         -1.78253003e-01,   1.40623499e-01,  -4.15986874e-01,\n",
       "         -1.63933407e-01,  -1.91572898e-01,  -3.08806340e-02,\n",
       "          2.71636371e-01,  -5.79291636e-01,   4.97413541e-02,\n",
       "         -3.24973972e-01,  -1.00708901e-01,  -2.76051256e-01,\n",
       "         -1.33460232e-01,  -2.48932778e-01,   3.02439320e-01,\n",
       "          5.44541170e-03,   4.25385014e-01,  -2.61608756e-01,\n",
       "         -2.53742574e-01,   2.97487308e-01,  -1.33012891e-01,\n",
       "         -3.81907179e-01,  -4.94331538e-01,   9.36231549e-01,\n",
       "         -6.11964418e-01,  -6.23508172e-02,   1.94209169e-01,\n",
       "          8.49950507e-02,  -1.30711703e-01,  -1.37828900e-01,\n",
       "         -8.80492241e-01,   3.45745211e-01,   5.43956669e-01,\n",
       "          1.90291088e-01,  -5.56962146e-02,  -1.88243370e-01,\n",
       "         -1.55958661e-01,  -1.10228179e-01,   7.92319328e-01,\n",
       "          9.57826315e-02,   1.44159584e-01,  -1.17977238e-01,\n",
       "          1.99768970e-01,  -1.71573035e-02,  -1.66804175e-01,\n",
       "         -1.71472613e-01,   4.92846328e-02,   1.40961304e-01,\n",
       "         -3.20416800e-02,   6.70675051e-02,  -1.35125901e-01,\n",
       "         -1.45834864e-04,   2.35790321e-01,  -4.38765510e-01,\n",
       "          5.81361881e-02,  -1.14491403e-01,  -1.16292638e-01,\n",
       "         -3.11576211e-01,   2.33017736e-01,  -1.13955775e-01,\n",
       "         -1.79502792e-01,   2.61283077e-02,   2.53282298e-01,\n",
       "         -1.67465979e-01,   6.19815065e-02,  -7.03262637e-02,\n",
       "          5.04536728e-02,   2.15365323e-02,   1.41346358e-01,\n",
       "          5.50804306e-02,   2.33017736e-01,  -1.48424614e-01,\n",
       "         -4.41979560e-02,  -1.67465979e-01,   5.04536728e-02,\n",
       "          2.15365323e-02,   5.50804306e-02,  -5.12541482e-01,\n",
       "         -2.41492325e-03,  -3.34166600e-02,   1.17404892e-01,\n",
       "          1.08456317e-01,   1.13942070e-01,   5.54510181e-02,\n",
       "          6.06488504e-02,   6.36108167e-02,  -1.27251082e-01,\n",
       "          1.68247257e-01,  -1.21372513e-02,  -2.26532279e-01,\n",
       "         -3.58315832e-02,   1.17404892e-01,   5.54510181e-02,\n",
       "          8.95077744e-02,   1.44705962e-01,   2.90001479e-01,\n",
       "          2.67068731e-02,   5.05926324e-02,  -9.13800220e-02,\n",
       "         -7.22411327e-02,  -3.48385970e-01,   2.28533873e-01,\n",
       "          1.18910693e-01,  -6.44329954e-02,  -4.07937159e-01,\n",
       "          4.75491256e-02,   4.10571750e-01,  -1.08628747e-01,\n",
       "         -2.24566718e-01,  -4.99721396e-01,   3.20740038e-01,\n",
       "          4.55154160e-01,   2.46349225e-01,  -5.22522204e-01,\n",
       "          6.73235778e-03,  -3.36388784e-01,  -2.53837849e-01,\n",
       "          3.31994611e-01,   1.70329824e-01,  -5.98997023e-02,\n",
       "          1.41069365e-01,   8.79020202e-02,   1.65935652e-01,\n",
       "         -2.53837849e-01,  -3.31544559e-01,   6.20186794e-02,\n",
       "         -1.46761304e-02,  -6.10096461e-02,   2.13577466e-01,\n",
       "          1.31634013e-01,   2.07477849e-01,   9.96646270e-02,\n",
       "         -1.00082391e-01,   1.49467332e-01,   4.10882220e-01,\n",
       "          8.27951832e-02,  -1.27363758e-01,   4.08144609e-02,\n",
       "         -3.72651539e-01,  -1.10894322e-01,  -1.11869746e-01,\n",
       "         -1.68240092e-01],\n",
       "       [ -6.72609285e-02,  -1.50180493e-01,  -6.45381752e-02,\n",
       "          6.57318688e-02,   3.06186916e-01,   5.45499170e-01,\n",
       "          1.14943846e-01,   4.53237337e-01,   2.03386689e-01,\n",
       "          1.42589715e-01,   1.93378368e-01,   3.37716698e-02,\n",
       "          4.46345131e-01,  -8.24880337e-02,   2.05026628e-01,\n",
       "         -1.57867271e-01,   3.25464481e-01,   1.51615984e-01,\n",
       "          2.79955498e-01,   3.27738834e-01,   3.76757649e-01,\n",
       "          3.30992087e-01,   6.20614316e-01,   4.98565048e-01,\n",
       "          5.94031605e-02,  -1.53266001e-01,  -7.63386753e-02,\n",
       "         -8.51890755e-02,  -3.15756147e-01,   2.42913915e-01,\n",
       "          2.32205156e-01,  -6.78372079e-02,   1.63865041e-01,\n",
       "          7.79050205e-02,   3.49365635e-01,  -7.50773502e-01,\n",
       "          3.21357764e-02,   5.46029920e-02,   1.86682898e-01,\n",
       "          1.63868265e-02,   2.29528313e-01,  -3.90293672e-02,\n",
       "          1.00415320e+00,  -2.37370668e-01,  -4.36076916e-01,\n",
       "          1.90694477e-01,  -1.19763073e-01,   1.53104629e-01,\n",
       "          4.16922527e-01,  -1.04670863e-01,  -6.59630844e-01,\n",
       "         -9.66537354e-02,  -1.22602820e-01,  -1.44910342e-01,\n",
       "          1.69564125e-01,   1.05589448e-02,   3.11370496e-01,\n",
       "         -8.14406403e-02,   1.91938482e-01,   6.26535340e-02,\n",
       "          1.29768351e-01,  -1.97662450e-01,   1.06488237e-01,\n",
       "         -7.10353146e-02,  -1.43946170e-02,   1.78710793e-02,\n",
       "          5.79873346e-02,   9.29782895e-02,  -3.29817779e-02,\n",
       "         -3.86992114e-02,  -2.04525693e-01,  -1.11708484e-01,\n",
       "          3.41813790e-01,   6.98419042e-03,  -5.32767909e-01,\n",
       "          2.59311592e-01,   1.89799531e-01,   1.91026551e-01,\n",
       "         -1.94200791e-01,   2.10002181e-02,  -2.64296218e-02,\n",
       "          9.83960040e-02,  -2.04525693e-01,  -1.77991906e-01,\n",
       "          1.98010741e-01,   2.59311592e-01,  -1.94200791e-01,\n",
       "          2.10002181e-02,   9.83960040e-02,   9.19076938e-01,\n",
       "         -1.68766018e-01,   1.34120270e-01,  -1.14096042e-01,\n",
       "         -7.26179310e-01,  -9.44571651e-02,  -7.99411824e-02,\n",
       "          9.44758217e-02,   7.46911664e-02,   9.54754702e-02,\n",
       "         -2.76957716e-03,  -1.31630207e-01,   1.73131630e-01,\n",
       "         -3.46457479e-02,  -1.14096042e-01,  -7.99411824e-02,\n",
       "          5.55515078e-02,  -3.09245101e-01,  -3.32788344e-01,\n",
       "          2.80703191e-01,  -7.86786737e-02,   2.26302506e-01,\n",
       "         -2.45315055e-01,   4.59021643e-01,  -1.74863191e-01,\n",
       "         -4.06337576e-01,   1.87817231e-01,  -1.71804285e-01,\n",
       "          2.75737040e-02,  -1.00743083e-02,   1.05970293e-01,\n",
       "          4.41718299e-01,   1.93109737e+00,  -8.42996843e-01,\n",
       "         -6.71694980e-01,  -6.36489720e-01,   2.20084338e-01,\n",
       "          8.11565001e-02,   5.00815415e-01,   6.66427340e-02,\n",
       "         -6.67996708e-01,   7.18878310e-02,   1.77474792e-01,\n",
       "         -2.29980399e-01,   2.86508932e-02,  -9.52934618e-02,\n",
       "          6.66427340e-02,   1.37126977e-02,   8.85652752e-03,\n",
       "         -1.47801567e-01,   8.55665482e-02,  -6.30342419e-01,\n",
       "          6.70008378e-01,  -5.23843342e-02,  -1.83385751e-01,\n",
       "         -1.61696068e-01,  -1.04621652e-01,  -2.32935608e-01,\n",
       "         -5.80653903e-02,   1.07799267e-01,  -1.13833961e-01,\n",
       "          4.16325046e-01,   1.78514667e-01,   1.71712754e-01,\n",
       "          3.25711952e-02]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfmlr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try using the 'lbfgs' solver instead of the 'newton-cg.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 15 µs\n",
      "using mask\n",
      "BEST {'C': 0.1} 0.73354978355 [mean: 0.71876, std: 0.00347, params: {'C': 0.001}, mean: 0.72912, std: 0.00324, params: {'C': 0.01}, mean: 0.73355, std: 0.00356, params: {'C': 0.1}, mean: 0.73324, std: 0.00298, params: {'C': 1.0}, mean: 0.73338, std: 0.00300, params: {'C': 10.0}, mean: 0.73336, std: 0.00297, params: {'C': 100.0}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.74\n",
      "Accuracy on test data:     0.73\n",
      "[[8677   41  924]\n",
      " [ 988   81  226]\n",
      " [2557   31 4295]]\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "clfmlr_lbfgs, Xtrain_lbfgs, ytrain_lbfgs, Xtest_lbfgs, ytest__lbfgs = do_classify(LogisticRegression(penalty=\"l2\",solver='lbfgs', multi_class='multinomial'), \n",
    "                                                   {\"C\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}, df_formatted,feat_cols, u'status_group',1, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try the regression again on the non-standardized features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_copy_formatted = pd.get_dummies(df_copy, columns=CATEGORICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 16.9 µs\n",
      "using mask\n",
      "BEST {'C': 10.0} 0.733597883598 [mean: 0.71835, std: 0.00373, params: {'C': 0.001}, mean: 0.72912, std: 0.00330, params: {'C': 0.01}, mean: 0.73355, std: 0.00384, params: {'C': 0.1}, mean: 0.73345, std: 0.00340, params: {'C': 1.0}, mean: 0.73360, std: 0.00307, params: {'C': 10.0}, mean: 0.73350, std: 0.00308, params: {'C': 100.0}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.74\n",
      "Accuracy on test data:     0.73\n",
      "[[8649   44  949]\n",
      " [ 970   96  229]\n",
      " [2518   35 4330]]\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "clfmlr1, Xtrain1, ytrain1, Xtest1, ytest1 = do_classify(LogisticRegression(penalty=\"l2\",solver='newton-cg', multi_class='multinomial'), \n",
    "                                                   {\"C\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}, df_copy_formatted,feat_cols, u'status_group',1, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1e+03 ns, total: 6 µs\n",
      "Wall time: 22.9 µs\n",
      "using mask\n",
      "BEST {'C': 100.0} 0.713949013949 [mean: 0.71253, std: 0.00503, params: {'C': 0.001}, mean: 0.71371, std: 0.00440, params: {'C': 0.01}, mean: 0.71205, std: 0.00354, params: {'C': 0.1}, mean: 0.71152, std: 0.00473, params: {'C': 1.0}, mean: 0.71335, std: 0.00654, params: {'C': 10.0}, mean: 0.71395, std: 0.00714, params: {'C': 100.0}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.71\n",
      "Accuracy on test data:     0.71\n",
      "[[8491    1 1150]\n",
      " [ 978    1  316]\n",
      " [2779    1 4103]]\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "clfmlr_lbfgs1, Xtrain_lbfgs1, ytrain_lbfgs1, Xtest_lbfgs1, ytest__lbfgs1 = do_classify(LogisticRegression(penalty=\"l2\",solver='lbfgs', multi_class='multinomial'), \n",
    "                                                   {\"C\": [0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}, df_copy_formatted,feat_cols, u'status_group',1, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we run a Random Forest, optimizing for the number of trees and the number of features to consider for the best split each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:5: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST {'n_estimators': 19} 0.775157654197 [mean: 0.72833, std: 0.00083, params: {'n_estimators': 1}, mean: 0.74226, std: 0.00480, params: {'n_estimators': 2}, mean: 0.75475, std: 0.00339, params: {'n_estimators': 3}, mean: 0.75988, std: 0.00219, params: {'n_estimators': 4}, mean: 0.76246, std: 0.00271, params: {'n_estimators': 5}, mean: 0.76741, std: 0.00355, params: {'n_estimators': 6}, mean: 0.76726, std: 0.00414, params: {'n_estimators': 7}, mean: 0.76844, std: 0.00236, params: {'n_estimators': 8}, mean: 0.76959, std: 0.00292, params: {'n_estimators': 9}, mean: 0.77053, std: 0.00252, params: {'n_estimators': 10}, mean: 0.77259, std: 0.00269, params: {'n_estimators': 11}, mean: 0.77458, std: 0.00554, params: {'n_estimators': 12}, mean: 0.77424, std: 0.00350, params: {'n_estimators': 13}, mean: 0.77482, std: 0.00265, params: {'n_estimators': 14}, mean: 0.77111, std: 0.00265, params: {'n_estimators': 15}, mean: 0.77495, std: 0.00308, params: {'n_estimators': 16}, mean: 0.77211, std: 0.00314, params: {'n_estimators': 17}, mean: 0.77465, std: 0.00497, params: {'n_estimators': 18}, mean: 0.77516, std: 0.00206, params: {'n_estimators': 19}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.96\n",
      "Accuracy on test data:     0.78\n",
      "[[8245  345 1052]\n",
      " [ 637  456  202]\n",
      " [1504  149 5230]]\n",
      "########################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/lilyzhang/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:676: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clfForest = RandomForestClassifier()\n",
    "\n",
    "parameters = {\"n_estimators\": range(1, 20)}\n",
    "clfForest, Xtrain, ytrain, Xtest, ytest = do_classify(clfForest, parameters, \n",
    "                                                       df_formatted, feat_cols, 'status_group', 1, mask=mask, \n",
    "                                                       n_jobs = 4, score_func='f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get number of trees (n_estimators)\n",
    "len(clfForest.estimators_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this is at the maximum of our range. Thus, we increase the the range that we optimize over during our GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n",
      "BEST {'n_estimators': 35} 0.778466619244 [mean: 0.77501, std: 0.00407, params: {'n_estimators': 18}, mean: 0.77566, std: 0.00340, params: {'n_estimators': 19}, mean: 0.77478, std: 0.00217, params: {'n_estimators': 20}, mean: 0.77414, std: 0.00359, params: {'n_estimators': 21}, mean: 0.77384, std: 0.00377, params: {'n_estimators': 22}, mean: 0.77621, std: 0.00379, params: {'n_estimators': 23}, mean: 0.77677, std: 0.00243, params: {'n_estimators': 24}, mean: 0.77611, std: 0.00332, params: {'n_estimators': 25}, mean: 0.77626, std: 0.00266, params: {'n_estimators': 26}, mean: 0.77535, std: 0.00259, params: {'n_estimators': 27}, mean: 0.77447, std: 0.00437, params: {'n_estimators': 28}, mean: 0.77710, std: 0.00270, params: {'n_estimators': 29}, mean: 0.77541, std: 0.00309, params: {'n_estimators': 30}, mean: 0.77555, std: 0.00386, params: {'n_estimators': 31}, mean: 0.77681, std: 0.00338, params: {'n_estimators': 32}, mean: 0.77601, std: 0.00288, params: {'n_estimators': 33}, mean: 0.77682, std: 0.00241, params: {'n_estimators': 34}, mean: 0.77847, std: 0.00437, params: {'n_estimators': 35}, mean: 0.77714, std: 0.00389, params: {'n_estimators': 36}, mean: 0.77692, std: 0.00216, params: {'n_estimators': 37}, mean: 0.77659, std: 0.00204, params: {'n_estimators': 38}, mean: 0.77637, std: 0.00329, params: {'n_estimators': 39}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.97\n",
      "Accuracy on test data:     0.79\n",
      "[[8251  351 1040]\n",
      " [ 634  444  217]\n",
      " [1433  149 5301]]\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "clfForest1 = RandomForestClassifier()\n",
    "\n",
    "parameters = {\"n_estimators\": range(18, 40)}\n",
    "clfForest1, Xtrain, ytrain, Xtest, ytest = do_classify(clfForest1, parameters, \n",
    "                                                       df_formatted, feat_cols, 'status_group', 1, mask=mask, \n",
    "                                                       n_jobs = 4, score_func='f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that we have not hit the boundary of the range we gave and indeed found an optimal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clfForest1.estimators_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above classifier, we set the max_depth to None, meaning nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples (in this case, 2). We try limiting the max depth by increasing the min_samples_split size to see if this improves our performance, especially since it seems like the above classifier is overfitting to the training set. Thus we add min_sample_split to parameters to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n",
      "BEST {'min_samples_split': 7, 'n_estimators': 35} 0.785534530765 [mean: 0.77548, std: 0.00265, params: {'min_samples_split': 2, 'n_estimators': 18}, mean: 0.77365, std: 0.00286, params: {'min_samples_split': 2, 'n_estimators': 19}, mean: 0.77474, std: 0.00464, params: {'min_samples_split': 2, 'n_estimators': 20}, mean: 0.77358, std: 0.00425, params: {'min_samples_split': 2, 'n_estimators': 21}, mean: 0.77479, std: 0.00304, params: {'min_samples_split': 2, 'n_estimators': 22}, mean: 0.77505, std: 0.00263, params: {'min_samples_split': 2, 'n_estimators': 23}, mean: 0.77447, std: 0.00370, params: {'min_samples_split': 2, 'n_estimators': 24}, mean: 0.77594, std: 0.00305, params: {'min_samples_split': 2, 'n_estimators': 25}, mean: 0.77633, std: 0.00371, params: {'min_samples_split': 2, 'n_estimators': 26}, mean: 0.77552, std: 0.00422, params: {'min_samples_split': 2, 'n_estimators': 27}, mean: 0.77548, std: 0.00369, params: {'min_samples_split': 2, 'n_estimators': 28}, mean: 0.77557, std: 0.00266, params: {'min_samples_split': 2, 'n_estimators': 29}, mean: 0.77677, std: 0.00378, params: {'min_samples_split': 2, 'n_estimators': 30}, mean: 0.77601, std: 0.00261, params: {'min_samples_split': 2, 'n_estimators': 31}, mean: 0.77708, std: 0.00353, params: {'min_samples_split': 2, 'n_estimators': 32}, mean: 0.77655, std: 0.00232, params: {'min_samples_split': 2, 'n_estimators': 33}, mean: 0.77722, std: 0.00287, params: {'min_samples_split': 2, 'n_estimators': 34}, mean: 0.77656, std: 0.00321, params: {'min_samples_split': 2, 'n_estimators': 35}, mean: 0.77633, std: 0.00327, params: {'min_samples_split': 2, 'n_estimators': 36}, mean: 0.77681, std: 0.00388, params: {'min_samples_split': 2, 'n_estimators': 37}, mean: 0.77690, std: 0.00273, params: {'min_samples_split': 2, 'n_estimators': 38}, mean: 0.77786, std: 0.00449, params: {'min_samples_split': 2, 'n_estimators': 39}, mean: 0.77847, std: 0.00224, params: {'min_samples_split': 3, 'n_estimators': 18}, mean: 0.78153, std: 0.00221, params: {'min_samples_split': 3, 'n_estimators': 19}, mean: 0.77748, std: 0.00338, params: {'min_samples_split': 3, 'n_estimators': 20}, mean: 0.77883, std: 0.00287, params: {'min_samples_split': 3, 'n_estimators': 21}, mean: 0.77940, std: 0.00229, params: {'min_samples_split': 3, 'n_estimators': 22}, mean: 0.77764, std: 0.00218, params: {'min_samples_split': 3, 'n_estimators': 23}, mean: 0.78009, std: 0.00365, params: {'min_samples_split': 3, 'n_estimators': 24}, mean: 0.78192, std: 0.00170, params: {'min_samples_split': 3, 'n_estimators': 25}, mean: 0.77875, std: 0.00273, params: {'min_samples_split': 3, 'n_estimators': 26}, mean: 0.77836, std: 0.00421, params: {'min_samples_split': 3, 'n_estimators': 27}, mean: 0.78001, std: 0.00317, params: {'min_samples_split': 3, 'n_estimators': 28}, mean: 0.77958, std: 0.00307, params: {'min_samples_split': 3, 'n_estimators': 29}, mean: 0.78043, std: 0.00451, params: {'min_samples_split': 3, 'n_estimators': 30}, mean: 0.77943, std: 0.00343, params: {'min_samples_split': 3, 'n_estimators': 31}, mean: 0.77930, std: 0.00239, params: {'min_samples_split': 3, 'n_estimators': 32}, mean: 0.78164, std: 0.00292, params: {'min_samples_split': 3, 'n_estimators': 33}, mean: 0.78098, std: 0.00237, params: {'min_samples_split': 3, 'n_estimators': 34}, mean: 0.77970, std: 0.00186, params: {'min_samples_split': 3, 'n_estimators': 35}, mean: 0.78065, std: 0.00200, params: {'min_samples_split': 3, 'n_estimators': 36}, mean: 0.77943, std: 0.00379, params: {'min_samples_split': 3, 'n_estimators': 37}, mean: 0.78122, std: 0.00357, params: {'min_samples_split': 3, 'n_estimators': 38}, mean: 0.77940, std: 0.00290, params: {'min_samples_split': 3, 'n_estimators': 39}, mean: 0.78045, std: 0.00387, params: {'min_samples_split': 4, 'n_estimators': 18}, mean: 0.78069, std: 0.00174, params: {'min_samples_split': 4, 'n_estimators': 19}, mean: 0.78184, std: 0.00161, params: {'min_samples_split': 4, 'n_estimators': 20}, mean: 0.78125, std: 0.00319, params: {'min_samples_split': 4, 'n_estimators': 21}, mean: 0.78084, std: 0.00281, params: {'min_samples_split': 4, 'n_estimators': 22}, mean: 0.78209, std: 0.00337, params: {'min_samples_split': 4, 'n_estimators': 23}, mean: 0.78110, std: 0.00225, params: {'min_samples_split': 4, 'n_estimators': 24}, mean: 0.78145, std: 0.00233, params: {'min_samples_split': 4, 'n_estimators': 25}, mean: 0.78144, std: 0.00361, params: {'min_samples_split': 4, 'n_estimators': 26}, mean: 0.78172, std: 0.00332, params: {'min_samples_split': 4, 'n_estimators': 27}, mean: 0.78256, std: 0.00205, params: {'min_samples_split': 4, 'n_estimators': 28}, mean: 0.78157, std: 0.00268, params: {'min_samples_split': 4, 'n_estimators': 29}, mean: 0.78136, std: 0.00153, params: {'min_samples_split': 4, 'n_estimators': 30}, mean: 0.78312, std: 0.00221, params: {'min_samples_split': 4, 'n_estimators': 31}, mean: 0.78290, std: 0.00272, params: {'min_samples_split': 4, 'n_estimators': 32}, mean: 0.78270, std: 0.00416, params: {'min_samples_split': 4, 'n_estimators': 33}, mean: 0.78308, std: 0.00192, params: {'min_samples_split': 4, 'n_estimators': 34}, mean: 0.78123, std: 0.00365, params: {'min_samples_split': 4, 'n_estimators': 35}, mean: 0.78208, std: 0.00322, params: {'min_samples_split': 4, 'n_estimators': 36}, mean: 0.78373, std: 0.00315, params: {'min_samples_split': 4, 'n_estimators': 37}, mean: 0.78339, std: 0.00300, params: {'min_samples_split': 4, 'n_estimators': 38}, mean: 0.78309, std: 0.00191, params: {'min_samples_split': 4, 'n_estimators': 39}, mean: 0.78089, std: 0.00336, params: {'min_samples_split': 5, 'n_estimators': 18}, mean: 0.78036, std: 0.00349, params: {'min_samples_split': 5, 'n_estimators': 19}, mean: 0.78171, std: 0.00266, params: {'min_samples_split': 5, 'n_estimators': 20}, mean: 0.78136, std: 0.00146, params: {'min_samples_split': 5, 'n_estimators': 21}, mean: 0.78300, std: 0.00462, params: {'min_samples_split': 5, 'n_estimators': 22}, mean: 0.78309, std: 0.00240, params: {'min_samples_split': 5, 'n_estimators': 23}, mean: 0.78233, std: 0.00230, params: {'min_samples_split': 5, 'n_estimators': 24}, mean: 0.78070, std: 0.00113, params: {'min_samples_split': 5, 'n_estimators': 25}, mean: 0.78153, std: 0.00296, params: {'min_samples_split': 5, 'n_estimators': 26}, mean: 0.78019, std: 0.00264, params: {'min_samples_split': 5, 'n_estimators': 27}, mean: 0.78200, std: 0.00275, params: {'min_samples_split': 5, 'n_estimators': 28}, mean: 0.78297, std: 0.00427, params: {'min_samples_split': 5, 'n_estimators': 29}, mean: 0.78346, std: 0.00121, params: {'min_samples_split': 5, 'n_estimators': 30}, mean: 0.78393, std: 0.00276, params: {'min_samples_split': 5, 'n_estimators': 31}, mean: 0.78302, std: 0.00322, params: {'min_samples_split': 5, 'n_estimators': 32}, mean: 0.78314, std: 0.00202, params: {'min_samples_split': 5, 'n_estimators': 33}, mean: 0.78205, std: 0.00152, params: {'min_samples_split': 5, 'n_estimators': 34}, mean: 0.78420, std: 0.00276, params: {'min_samples_split': 5, 'n_estimators': 35}, mean: 0.78513, std: 0.00214, params: {'min_samples_split': 5, 'n_estimators': 36}, mean: 0.78398, std: 0.00113, params: {'min_samples_split': 5, 'n_estimators': 37}, mean: 0.78416, std: 0.00215, params: {'min_samples_split': 5, 'n_estimators': 38}, mean: 0.78419, std: 0.00222, params: {'min_samples_split': 5, 'n_estimators': 39}, mean: 0.77972, std: 0.00188, params: {'min_samples_split': 6, 'n_estimators': 18}, mean: 0.78123, std: 0.00303, params: {'min_samples_split': 6, 'n_estimators': 19}, mean: 0.78183, std: 0.00202, params: {'min_samples_split': 6, 'n_estimators': 20}, mean: 0.78233, std: 0.00167, params: {'min_samples_split': 6, 'n_estimators': 21}, mean: 0.78286, std: 0.00216, params: {'min_samples_split': 6, 'n_estimators': 22}, mean: 0.78390, std: 0.00195, params: {'min_samples_split': 6, 'n_estimators': 23}, mean: 0.78385, std: 0.00183, params: {'min_samples_split': 6, 'n_estimators': 24}, mean: 0.78396, std: 0.00180, params: {'min_samples_split': 6, 'n_estimators': 25}, mean: 0.78375, std: 0.00261, params: {'min_samples_split': 6, 'n_estimators': 26}, mean: 0.78313, std: 0.00193, params: {'min_samples_split': 6, 'n_estimators': 27}, mean: 0.78177, std: 0.00255, params: {'min_samples_split': 6, 'n_estimators': 28}, mean: 0.78508, std: 0.00232, params: {'min_samples_split': 6, 'n_estimators': 29}, mean: 0.78405, std: 0.00119, params: {'min_samples_split': 6, 'n_estimators': 30}, mean: 0.78258, std: 0.00242, params: {'min_samples_split': 6, 'n_estimators': 31}, mean: 0.78353, std: 0.00136, params: {'min_samples_split': 6, 'n_estimators': 32}, mean: 0.78361, std: 0.00255, params: {'min_samples_split': 6, 'n_estimators': 33}, mean: 0.78477, std: 0.00149, params: {'min_samples_split': 6, 'n_estimators': 34}, mean: 0.78196, std: 0.00198, params: {'min_samples_split': 6, 'n_estimators': 35}, mean: 0.78270, std: 0.00122, params: {'min_samples_split': 6, 'n_estimators': 36}, mean: 0.78390, std: 0.00253, params: {'min_samples_split': 6, 'n_estimators': 37}, mean: 0.78450, std: 0.00211, params: {'min_samples_split': 6, 'n_estimators': 38}, mean: 0.78498, std: 0.00188, params: {'min_samples_split': 6, 'n_estimators': 39}, mean: 0.78100, std: 0.00255, params: {'min_samples_split': 7, 'n_estimators': 18}, mean: 0.78136, std: 0.00198, params: {'min_samples_split': 7, 'n_estimators': 19}, mean: 0.78209, std: 0.00257, params: {'min_samples_split': 7, 'n_estimators': 20}, mean: 0.78198, std: 0.00264, params: {'min_samples_split': 7, 'n_estimators': 21}, mean: 0.78274, std: 0.00303, params: {'min_samples_split': 7, 'n_estimators': 22}, mean: 0.78333, std: 0.00164, params: {'min_samples_split': 7, 'n_estimators': 23}, mean: 0.78457, std: 0.00241, params: {'min_samples_split': 7, 'n_estimators': 24}, mean: 0.78303, std: 0.00302, params: {'min_samples_split': 7, 'n_estimators': 25}, mean: 0.78224, std: 0.00294, params: {'min_samples_split': 7, 'n_estimators': 26}, mean: 0.78312, std: 0.00294, params: {'min_samples_split': 7, 'n_estimators': 27}, mean: 0.78196, std: 0.00227, params: {'min_samples_split': 7, 'n_estimators': 28}, mean: 0.78391, std: 0.00256, params: {'min_samples_split': 7, 'n_estimators': 29}, mean: 0.78355, std: 0.00175, params: {'min_samples_split': 7, 'n_estimators': 30}, mean: 0.78547, std: 0.00198, params: {'min_samples_split': 7, 'n_estimators': 31}, mean: 0.78436, std: 0.00196, params: {'min_samples_split': 7, 'n_estimators': 32}, mean: 0.78437, std: 0.00364, params: {'min_samples_split': 7, 'n_estimators': 33}, mean: 0.78316, std: 0.00241, params: {'min_samples_split': 7, 'n_estimators': 34}, mean: 0.78553, std: 0.00141, params: {'min_samples_split': 7, 'n_estimators': 35}, mean: 0.78406, std: 0.00141, params: {'min_samples_split': 7, 'n_estimators': 36}, mean: 0.78426, std: 0.00245, params: {'min_samples_split': 7, 'n_estimators': 37}, mean: 0.78329, std: 0.00248, params: {'min_samples_split': 7, 'n_estimators': 38}, mean: 0.78362, std: 0.00130, params: {'min_samples_split': 7, 'n_estimators': 39}, mean: 0.78031, std: 0.00327, params: {'min_samples_split': 8, 'n_estimators': 18}, mean: 0.78178, std: 0.00224, params: {'min_samples_split': 8, 'n_estimators': 19}, mean: 0.78204, std: 0.00256, params: {'min_samples_split': 8, 'n_estimators': 20}, mean: 0.78134, std: 0.00386, params: {'min_samples_split': 8, 'n_estimators': 21}, mean: 0.78250, std: 0.00247, params: {'min_samples_split': 8, 'n_estimators': 22}, mean: 0.78260, std: 0.00213, params: {'min_samples_split': 8, 'n_estimators': 23}, mean: 0.78299, std: 0.00227, params: {'min_samples_split': 8, 'n_estimators': 24}, mean: 0.78135, std: 0.00195, params: {'min_samples_split': 8, 'n_estimators': 25}, mean: 0.78336, std: 0.00202, params: {'min_samples_split': 8, 'n_estimators': 26}, mean: 0.78335, std: 0.00332, params: {'min_samples_split': 8, 'n_estimators': 27}, mean: 0.78275, std: 0.00220, params: {'min_samples_split': 8, 'n_estimators': 28}, mean: 0.78177, std: 0.00222, params: {'min_samples_split': 8, 'n_estimators': 29}, mean: 0.78263, std: 0.00200, params: {'min_samples_split': 8, 'n_estimators': 30}, mean: 0.78299, std: 0.00180, params: {'min_samples_split': 8, 'n_estimators': 31}, mean: 0.78415, std: 0.00203, params: {'min_samples_split': 8, 'n_estimators': 32}, mean: 0.78312, std: 0.00245, params: {'min_samples_split': 8, 'n_estimators': 33}, mean: 0.78339, std: 0.00359, params: {'min_samples_split': 8, 'n_estimators': 34}, mean: 0.78326, std: 0.00283, params: {'min_samples_split': 8, 'n_estimators': 35}, mean: 0.78326, std: 0.00328, params: {'min_samples_split': 8, 'n_estimators': 36}, mean: 0.78296, std: 0.00263, params: {'min_samples_split': 8, 'n_estimators': 37}, mean: 0.78371, std: 0.00323, params: {'min_samples_split': 8, 'n_estimators': 38}, mean: 0.78345, std: 0.00166, params: {'min_samples_split': 8, 'n_estimators': 39}, mean: 0.78019, std: 0.00367, params: {'min_samples_split': 9, 'n_estimators': 18}, mean: 0.78024, std: 0.00353, params: {'min_samples_split': 9, 'n_estimators': 19}, mean: 0.78181, std: 0.00177, params: {'min_samples_split': 9, 'n_estimators': 20}, mean: 0.78241, std: 0.00232, params: {'min_samples_split': 9, 'n_estimators': 21}, mean: 0.78196, std: 0.00244, params: {'min_samples_split': 9, 'n_estimators': 22}, mean: 0.78200, std: 0.00153, params: {'min_samples_split': 9, 'n_estimators': 23}, mean: 0.78349, std: 0.00260, params: {'min_samples_split': 9, 'n_estimators': 24}, mean: 0.78044, std: 0.00350, params: {'min_samples_split': 9, 'n_estimators': 25}, mean: 0.78158, std: 0.00212, params: {'min_samples_split': 9, 'n_estimators': 26}, mean: 0.78257, std: 0.00240, params: {'min_samples_split': 9, 'n_estimators': 27}, mean: 0.78163, std: 0.00139, params: {'min_samples_split': 9, 'n_estimators': 28}, mean: 0.78338, std: 0.00261, params: {'min_samples_split': 9, 'n_estimators': 29}, mean: 0.78219, std: 0.00337, params: {'min_samples_split': 9, 'n_estimators': 30}, mean: 0.78236, std: 0.00228, params: {'min_samples_split': 9, 'n_estimators': 31}, mean: 0.78427, std: 0.00285, params: {'min_samples_split': 9, 'n_estimators': 32}, mean: 0.78262, std: 0.00148, params: {'min_samples_split': 9, 'n_estimators': 33}, mean: 0.78289, std: 0.00178, params: {'min_samples_split': 9, 'n_estimators': 34}, mean: 0.78157, std: 0.00192, params: {'min_samples_split': 9, 'n_estimators': 35}, mean: 0.78164, std: 0.00209, params: {'min_samples_split': 9, 'n_estimators': 36}, mean: 0.78254, std: 0.00241, params: {'min_samples_split': 9, 'n_estimators': 37}, mean: 0.78324, std: 0.00185, params: {'min_samples_split': 9, 'n_estimators': 38}, mean: 0.78305, std: 0.00199, params: {'min_samples_split': 9, 'n_estimators': 39}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.90\n",
      "Accuracy on test data:     0.80\n",
      "[[8566  210  866]\n",
      " [ 709  387  199]\n",
      " [1546   96 5241]]\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "clfForest2 = RandomForestClassifier()\n",
    "\n",
    "parameters = {\"n_estimators\": range(18,40), \"min_samples_split\": range(2,10)}\n",
    "clfForest2, Xtrain, ytrain, Xtest, ytest = do_classify(clfForest2, parameters, \n",
    "                                                       df_formatted, feat_cols, 'status_group', 1, mask=mask, \n",
    "                                                       n_jobs = 4, score_func='f1')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
